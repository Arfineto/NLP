{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/robin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Mar 28 13:00:48 2018\n",
    "\n",
    "@author: rniel\n",
    "\"\"\"\n",
    "dataset_path = \"datasets/review_rating/\"\n",
    "\n",
    "def open_uci(x_=[],y_=[],choice=[\"movie\",\"amazon\",\"yelp\"]):\n",
    "    dataset_path = \"datasets/polarization/\"\n",
    "    if (\"movie\" in choice):\n",
    "        file  = open(dataset_path+\"imdb_labelled.txt\", \"rt\")\n",
    "        content = file.read()\n",
    "        contents=[]\n",
    "        contents=content.split(\"\\n\")\n",
    "        del contents[-1]\n",
    "        for c in contents:\n",
    "            temp=c.split(\"\\t\")\n",
    "            x_.append(temp[0])\n",
    "            y_.append(int(temp[1]))\n",
    "\n",
    "    if (\"amazon\" in choice):\n",
    "        file  = open(dataset_path+\"amazon_cells_labelled.txt\", \"rt\")\n",
    "        content = file.read()\n",
    "        contents=[]\n",
    "        contents=content.split(\"\\n\")\n",
    "        del contents[-1]\n",
    "\n",
    "        for c in contents:\n",
    "            temp=c.split(\"\\t\")\n",
    "            x_.append(temp[0])\n",
    "            y_.append(int(temp[1]))\n",
    "\n",
    "    if (\"yelp\" in choice):\n",
    "        file  = open(dataset_path+\"yelp_labelled.txt\", \"rt\")\n",
    "        content = file.read()\n",
    "        contents=[]\n",
    "        contents=content.split(\"\\n\")\n",
    "        del contents[-1]\n",
    "\n",
    "\n",
    "        for c in contents:\n",
    "            temp=c.split(\"\\t\")\n",
    "            x_.append(temp[0])\n",
    "            y_.append(int(temp[1]))\n",
    "    return x_,y_\n",
    "\n",
    "def open_book(x_=[],y_=[]):\n",
    "    file  = open(dataset_path+\"book.txt\", \"rt\")\n",
    "    \n",
    "    nb_duplicate = 0\n",
    "    \n",
    "    content = file.read()\n",
    "    contents=[]\n",
    "    contents=content.split(\"\\n\")\n",
    "    del contents[-1]\n",
    "    del contents[-1]\n",
    "    \n",
    "    for c in contents:\n",
    "        temp=c.split(\"\\t\")\n",
    "        if(temp[1] in x_):\n",
    "            nb_duplicate+=1\n",
    "        else : \n",
    "            x_.append(temp[1])\n",
    "            y_.append(int(temp[0]))  \n",
    "    return x_,y_\n",
    "\n",
    "def open_movie(x_=[],y_=[]):\n",
    "    file  = open(dataset_path+\"rt-polarity-neg.txt\", \"rt\",encoding = \"ISO-8859-1\")\n",
    "\n",
    "    content = file.read()\n",
    "    contents=[]\n",
    "    contents=content.split(\"\\n\")\n",
    "    del contents[-1]\n",
    "    del contents[-1]\n",
    "\n",
    "    for i in range(len(contents)):\n",
    "        x_.append(contents[i])\n",
    "        y_.append(0)\n",
    "\n",
    "    file  = open(dataset_path+\"rt-polarity-pos.txt\", \"rt\",encoding = \"ISO-8859-1\")\n",
    "    content = file.read()\n",
    "    contents=[]\n",
    "    contents=content.split(\"\\n\")\n",
    "    del contents[-1]\n",
    "    del contents[-1]\n",
    "\n",
    "    for i in range(len(contents)):\n",
    "        x_.append(contents[i])\n",
    "        y_.append(1)    \n",
    "    return x_,y_\n",
    "\n",
    "def pretreatment(sentences):\n",
    "    # This function take a list of sentences and treat them to remove all punctuation mark and higher case\n",
    "    to_delete = [\",\",\".\",\"-\",\"!\",\"?\",\":\",\"*\",\")\",\"(\",\"'\",'\"',\"\\n\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for t in to_delete:\n",
    "            sentences[i] = sentences[i].replace(t,\" \")\n",
    "\n",
    "    ret_sentences = []\n",
    "    for s in sentences:\n",
    "        ret_sentences.append(s.split(\" \"))\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        ret_sentences[i]=[w for w in ret_sentences[i] if w!=\"\"]\n",
    "\n",
    "    for i in range(len(ret_sentences)):\n",
    "        for j in range(len(ret_sentences[i])) :\n",
    "            ret_sentences[i][j]=ret_sentences[i][j].lower()\n",
    "    return ret_sentences\n",
    "    \n",
    "def vectorization(sentences,word2vec_model,word_length=300,max_len=150,adaptable_len=False):\n",
    "    \"\"\" This function transform an array of list of words (the splitted sentences) into a array of list of vectors \n",
    "            representing the words thanks to an already trained word2Vec model\n",
    "            \n",
    "        Keyword arguments:\n",
    "        sentences -- The different sentences you want to vectorize\n",
    "        word2vec_model -- An already trained gensim Word2Vec model\n",
    "        word_length -- The number of dimension of the vectors representing the words (default 300) \n",
    "        max_len -- The maximum length of a sentence (default 50) \n",
    "        adaptable_len -- A boolean allowing to adapt the maximum length to the longest sentence in your dataset\n",
    "    \"\"\"\n",
    "    sentences_v=[]\n",
    "    unusued_word=[]\n",
    "\n",
    "    sp_words = set(stopwords.words('english'))    \n",
    "    \n",
    "    for s in sentences:\n",
    "        temp=[]\n",
    "        for w in s :\n",
    "            if(w not in sp_words):\n",
    "                try :\n",
    "                    temp.append(np.float32(word2vec_model[w]))\n",
    "                except : \n",
    "                    unusued_word.append(w)\n",
    "        sentences_v.append(temp)\n",
    "    \n",
    "    sentences_v = pad_sequences(np.array(sentences_v),maxlen=max_len,padding =\"post\")    \n",
    "    return sentences_v,max_len\n",
    "\n",
    "def load_google_word2vec(vocabulary_size = 300000, path = 'lib/GoogleNews-vectors-negative300.bin'):\n",
    "    # load the google word2vec model\n",
    "    model = KeyedVectors.load_word2vec_format(path,binary = True,limit=vocabulary_size)  \n",
    "    return model\n",
    "\n",
    "def protocol_test(config,model,length_sentences,x_test=[],y_test=[]):\n",
    "\n",
    "    names = [\"amazon\",\"yelp\",\"movies\"]\n",
    "    mean = []\n",
    "    \n",
    "    for n in names :\n",
    "        x, y = open_uci([],[],choice = n)\n",
    "        sentences = []\n",
    "        for i in range(len(x)):\n",
    "            #if \"not\" in x[i]:\n",
    "                #x[i]= treatment_negation(x[i])\n",
    "            sentences.append(text_to_word_sequence(x[i]))\n",
    "\n",
    "        sentences_v,max_len = vectorization(sentences,model,word_length=300,max_len=length_sentences)\n",
    "        y_pred = config.predict(np.array(sentences_v))\n",
    "        y_pred = np.argmax(y_pred,axis=1)\n",
    "        cf = confusion_matrix(y,y_pred)\n",
    "        acc = (cf[0][0]+cf[1][1])/(cf[0][0]+cf[1][1]+cf[0][1]+cf[1][0])\n",
    "        print(\"Confusion matrix : \\n \"+ str (cf))\n",
    "        mean.append(acc)\n",
    "        print(\"Accuracy and loss for the \"+str(n)+\" dataset : \"+ str(acc) +\"\\n\")\n",
    "    \n",
    "    print(\"Mean for the 3 datasets = \"+str(np.mean(mean))+\"\\n\")\n",
    "    \n",
    "    \n",
    "    if (len(x_test)!=0 and len(y_test)!=0):\n",
    "        y_pred = np.argmax(config.predict(np.array(x_test)),axis=1)\n",
    "        print(np.argmax(y_test))\n",
    "        #cf = confusion_matrix(np.argmax(y_test),y_pred)\n",
    "        cf = confusion_matrix(y_test,y_pred)\n",
    "        \n",
    "        acc = (cf[0][0]+cf[1][1])/(cf[0][0]+cf[1][1]+cf[0][1]+cf[1][0])\n",
    "        print(\"Confusion matrix :\\n \"+str(cf))\n",
    "        print(\"Evaluation on the test set : \"+str(acc))\n",
    "        \n",
    "def protocol_test_embedding(config,tokenizer,length_sentences,x_test=[],y_test=[]):\n",
    "\n",
    "    names = [\"amazon\",\"yelp\",\"movies\"]\n",
    "    mean = []\n",
    "    \n",
    "    for n in names :\n",
    "        x, y = open_uci([],[],choice = n)\n",
    "        for i in range(len(x)) : \n",
    "            if(\"not\" in x[i]):\n",
    "                x[i] = treatment_negation(x[i])\n",
    "            \n",
    "            sentences_v = []        \n",
    "            for s in x :\n",
    "                sentences_v.append(text_to_word_sequence(s))\n",
    "        sentences_v = tokenize(sentences_v,tokenizer,length_sentences)\n",
    "        y_pred = config.predict(np.array(sentences_v))\n",
    "        y_pred = np.argmax(y_pred,axis=1)\n",
    "        print(len(y_pred))\n",
    "        cf = confusion_matrix(y,y_pred)\n",
    "        acc = (cf[0][0]+cf[1][1])/(cf[0][0]+cf[1][1]+cf[0][1]+cf[1][0])\n",
    "        print(\"Confusion matrix : \\n \"+ str (cf))\n",
    "        mean.append(acc)\n",
    "        print(\"Accuracy and loss for the \"+str(n)+\" dataset : \"+ str(acc) +\"\\n\")\n",
    "    \n",
    "    print(\"Mean for the 3 datasets = \"+str(np.mean(mean))+\"\\n\")\n",
    "        \n",
    "    if (len(x_test)!=0 and len(y_test)!=0):\n",
    "        y_pred = np.argmax(config.predict(np.array(x_test)),axis=1)\n",
    "        cf = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n",
    "        acc = (cf[0][0]+cf[1][1])/(cf[0][0]+cf[1][1]+cf[0][1]+cf[1][0])\n",
    "        print(\"Confusion matrix :\\n \"+str(cf))\n",
    "        print(\"Evaluation on the test set : \"+str(acc))\n",
    "\n",
    "def protocol_test_embedding_gensim(config,word2vec_model,length_sentences,x_test=[],y_test=[]):\n",
    "\n",
    "    names = [\"amazon\",\"yelp\",\"movies\"]\n",
    "    mean = []\n",
    "    \n",
    "    for n in names :\n",
    "        x, y = open_uci([],[],choice = n)\n",
    "        for i in range(len(x)) : \n",
    "            if(\"not\" in x[i]):\n",
    "                x[i] = treatment_negation(x[i])\n",
    "            \n",
    "            sentences_v = []        \n",
    "            for s in x :\n",
    "                sentences_v.append(text_to_word_sequence(s))\n",
    "        sentences_v = tokenize(word2vec_model,sentences_v,length_sentences)\n",
    "        y_pred = config.predict(np.array(sentences_v))\n",
    "        y_pred = np.argmax(y_pred,axis=1)\n",
    "        cf = confusion_matrix(y,y_pred)\n",
    "        acc = (cf[0][0]+cf[1][1])/(cf[0][0]+cf[1][1]+cf[0][1]+cf[1][0])\n",
    "        print(\"Confusion matrix : \\n \"+ str (cf))\n",
    "        mean.append(acc)\n",
    "        print(\"Accuracy and loss for the \"+str(n)+\" dataset : \"+ str(acc) +\"\\n\")\n",
    "    \n",
    "    print(\"Mean for the 3 datasets = \"+str(np.mean(mean))+\"\\n\")\n",
    "        \n",
    "    if (len(x_test)!=0 and len(y_test)!=0):\n",
    "        y_pred = np.argmax(config.predict(np.array(x_test)),axis=1)\n",
    "        cf = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n",
    "        acc = (cf[0][0]+cf[1][1])/(cf[0][0]+cf[1][1]+cf[0][1]+cf[1][0])\n",
    "        print(\"Confusion matrix :\\n \"+str(cf))\n",
    "        print(\"Evaluation on the test set : \"+str(acc))\n",
    "\n",
    "        \n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_negation_sentences(sentences):\n",
    "    ret_sentences = []\n",
    "    punctuation = [\",\",\".\",\"!\",\"?\",\":\"]\n",
    "\n",
    "    for s in sentences:\n",
    "        for p in punctuation :\n",
    "            s = s.replace(p,\" \"+p)\n",
    "        ret_sentences.append(s.split(\" \"))\n",
    "        \n",
    "    for s in ret_sentences:\n",
    "        for i in range(len(s)):\n",
    "            if (s[i] == 'not'):\n",
    "                j = i +1\n",
    "                if (j < len(s)):\n",
    "                    while (j< len(s) or (not(s[j] in punctuation) and s[j]!= \"\")):\n",
    "                        s[j] = \"not\"+s[j]\n",
    "                        j+=1\n",
    "                        if (j>=len(s)):\n",
    "                            break\n",
    "        for i in range(len(ret_sentences)):\n",
    "            ret_sentences[i] = \" \".join(ret_sentences[i])\n",
    "\n",
    "    return ret_sentences\n",
    "\n",
    "def treatment_negation(sentence):\n",
    "    \n",
    "    punctuation = [\",\",\".\",\"!\",\"?\",\":\"]\n",
    "    sp_words = set(stopwords.words('english'))    \n",
    "\n",
    "    for p in punctuation :\n",
    "        sentence = sentence.replace(p,\" \"+p)\n",
    "    \n",
    "    sentence = sentence.split(\" \")\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        if (sentence[i] == 'not'):\n",
    "            j = i\n",
    "            if (j < len(sentence)):\n",
    "                while (j< len(sentence) and (not(sentence[j] in punctuation) and sentence[j]!= \"\")):\n",
    "                    if (sentence[j] == \"not\"):\n",
    "                        sentence[j] = \"\"\n",
    "                        j+=1\n",
    "                    elif(not(sentence[j] in punctuation) and (sentence)) : \n",
    "                        sentence[j] = \"not\"+sentence[j]\n",
    "                        j+=1\n",
    "                        if (j>=len(sentence)):\n",
    "                            break\n",
    "                    else : \n",
    "                        j+=1\n",
    "    sentence = \" \".join(sentence)                    \n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x :23485\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Mar 28 13:00:48 2018\n",
    "\n",
    "@author: rniel\n",
    "\"\"\"\n",
    "import csv\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "i = 0\n",
    "with open(dataset_path+'Womens_Clothing.csv', 'r') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        if(i!=0):\n",
    "            x.append(row[4])\n",
    "            y.append(int(row[5]))\n",
    "        i+=1    \n",
    "del x[0]\n",
    "del y[0]\n",
    "\n",
    "for i in range(len(x)) :\n",
    "    if (\"not\" in x[i]):\n",
    "        x[i]=treatment_negation(x[i])\n",
    "\n",
    "print(\"Length of x :\"+str(len(x)))\n",
    "sentences = []\n",
    "for s in x :\n",
    "    sentences.append(text_to_word_sequence(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x :23485\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Mar 28 13:00:48 2018\n",
    "\n",
    "@author: rniel\n",
    "\"\"\"\n",
    "import csv\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "i = 0\n",
    "with open(dataset_path+'Womens_Clothing.csv', 'r') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        if(i!=0):\n",
    "            x.append(row[4])\n",
    "            y.append(int(row[5]))\n",
    "        i+=1    \n",
    "del x[0]\n",
    "del y[0]\n",
    "\n",
    "print(\"Length of x :\"+str(len(x)))\n",
    "sentences = []\n",
    "for s in x :\n",
    "    sentences.append(text_to_word_sequence(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming of the y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(y):\n",
    "    if(y>3):\n",
    "        return 0\n",
    "    if(y==3):\n",
    "        return 1\n",
    "    if(y<3):\n",
    "        return 2\n",
    "\n",
    "y = [transform(y_tmp) for y_tmp in y]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_x_y(x,y):\n",
    "    x_good = []\n",
    "    y_good = []\n",
    "    for i in range(len(x)):\n",
    "        if y[i] != 3:\n",
    "            x_good.append(x[i])\n",
    "            y_good.append(y[i])\n",
    "    return x_good,y_good\n",
    "\n",
    "def transform(y):\n",
    "    if(y>3):\n",
    "        return 1\n",
    "    if(y<3):\n",
    "        return 0\n",
    "\n",
    "sentences,y = transform_x_y(sentences,y)     \n",
    "y = [transform(y_tmp) for y_tmp in y]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "x = []\n",
    "y = []\n",
    "with open(dataset_path+'Movies_and_TV_5.json', 'r') as jsonfile:\n",
    "    i = 0\n",
    "    for line in jsonfile : \n",
    "        tmp = json.loads(line)\n",
    "        x.append(tmp['reviewText'])\n",
    "        y.append(int(tmp['overall']))\n",
    "        i+=1\n",
    "        if (i>1000):\n",
    "            break\n",
    "\n",
    "sentences = []\n",
    "for s in x :\n",
    "    sentences.append(text_to_word_sequence(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec_model = Word2Vec.load(\"variables/review_rating/not/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec_model = Word2Vec.load(\"variables/review_rating/word2vec/300/model_300_Movie_elec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = load_google_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(word2vec_model,sentences,length_sentences=None) :\n",
    "    sentences_t = []\n",
    "    unusued_words = []\n",
    "    for s in sentences :\n",
    "        sentence_tmp = []\n",
    "        for w in s :\n",
    "            try:\n",
    "                sentence_tmp.append(word2vec_model.wv.vocab[w].index) \n",
    "            except : \n",
    "                unusued_words.append(w)\n",
    "        sentences_t.append(sentence_tmp)\n",
    "    \n",
    "    sentences_ret = pad_sequences(np.array(sentences_t),maxlen=length_sentences)    \n",
    "    for i in range(len(sentences_ret)):\n",
    "        sentences_ret[i] = np.flip(sentences_ret[i],axis=0)\n",
    "        \n",
    "    return sentences_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_toke = tokenize(word2vec_model,sentences,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9001486, 13761630)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "WORD_LENGTH = 300\n",
    "sentences = pretreatment(x)\n",
    "model = Word2Vec(sentences, size=WORD_LENGTH, min_count=10, workers=4,sorted_vocab=1)\n",
    "model.train(sentences,total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of line of Electronics_5.json : 1689188\n",
      "Number of line of Movies_and_TV_5.json : 1697533\n"
     ]
    }
   ],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "print(\"Number of line of Electronics_5.json : \"+str(file_len(\"datasets/review_rating/Electronics_5.json\")))\n",
    "print(\"Number of line of Movies_and_TV_5.json : \" +str(file_len(\"datasets/review_rating/Movies_and_TV_5.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time        \n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "def amazon_word2vec_training(model,name_file,upper_bound,lower_bound,batch_size):\n",
    "    x = []\n",
    "    start_time = time.time()\n",
    "    mean = []\n",
    "    with open(\"datasets/review_rating/\"+name_file, 'r') as jsonfile:\n",
    "        i = 0\n",
    "        j = 1\n",
    "        for line in jsonfile :\n",
    "            if(i>lower_bound):\n",
    "                tmp = json.loads(line)\n",
    "                \"\"\"                if (\"not\" in tmp['reviewText']):\n",
    "                    x.append(treatment_negation(tmp['reviewText']))\n",
    "                else :\"\"\"\n",
    "                x.append(tmp['reviewText'])\n",
    "                if(j%batch_size == 0):\n",
    "                    sentences = pretreatment(x)\n",
    "                    model.build_vocab(sentences,update=True)\n",
    "                    model.train(sentences,total_examples = len(sentences),epochs = 10)\n",
    "                    j = 1\n",
    "                    x = []\n",
    "                    mean.append((time.time()-start_time)/60)\n",
    "                    print(\"ETA : \"+str(np.mean(mean)*((upper_bound-i)/batch_size))+\" mn\")\n",
    "                    print(\"Current vocab size  : \"+str(len(model.wv.vocab)))                    \n",
    "                    start_time=time.time()\n",
    "            \n",
    "            i+=1\n",
    "            j+=1\n",
    "            if(i>upper_bound):\n",
    "                break\n",
    "        model.save('variables/review_rating/word2vec/300/Model_300')\n",
    "        print(\"Model saved to the disk\")\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indices = np.arange(0,1700000,step=50000,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ieme step on 33\n",
      "ETA : 1.2257172566866874 mn\n",
      "Current vocab size  : 17695\n",
      "ETA : 0.9937115635871888 mn\n",
      "Current vocab size  : 18697\n",
      "ETA : 0.9024401582739089 mn\n",
      "Current vocab size  : 19519\n",
      "ETA : 0.7698069095214207 mn\n",
      "Current vocab size  : 20287\n",
      "ETA : 0.644639560713768 mn\n",
      "Current vocab size  : 20994\n",
      "ETA : 0.529883586857319 mn\n",
      "Current vocab size  : 21634\n",
      "ETA : 0.39598643728926064 mn\n",
      "Current vocab size  : 22042\n",
      "ETA : 0.26356578224658966 mn\n",
      "Current vocab size  : 22400\n",
      "ETA : 0.12948586883589075 mn\n",
      "Current vocab size  : 22697\n",
      "ETA : 0.0002544063766797384 mn\n",
      "Current vocab size  : 23036\n",
      "Model saved to the disk\n",
      "1 ieme step on 33\n",
      "ETA : 0.9492056180024147 mn\n",
      "Current vocab size  : 23324\n",
      "ETA : 0.8593710138368607 mn\n",
      "Current vocab size  : 23652\n",
      "ETA : 0.7952738237955836 mn\n",
      "Current vocab size  : 23960\n",
      "ETA : 0.727881087384224 mn\n",
      "Current vocab size  : 24260\n",
      "ETA : 0.6272310505700113 mn\n",
      "Current vocab size  : 24505\n",
      "ETA : 0.5052776167472204 mn\n",
      "Current vocab size  : 24769\n",
      "ETA : 0.3865769240438371 mn\n",
      "Current vocab size  : 25036\n",
      "ETA : 0.2593953616976738 mn\n",
      "Current vocab size  : 25282\n",
      "ETA : 0.12976053488210396 mn\n",
      "Current vocab size  : 25507\n",
      "ETA : 0.0002529177753130595 mn\n",
      "Current vocab size  : 25712\n",
      "Model saved to the disk\n",
      "2 ieme step on 33\n",
      "ETA : 1.220985091097355 mn\n",
      "Current vocab size  : 25909\n",
      "ETA : 1.0139968331456186 mn\n",
      "Current vocab size  : 26110\n",
      "ETA : 0.8926993270897867 mn\n",
      "Current vocab size  : 26363\n",
      "ETA : 0.791635156976382 mn\n",
      "Current vocab size  : 26625\n",
      "ETA : 0.6472241971755028 mn\n",
      "Current vocab size  : 26874\n",
      "ETA : 0.5182891280794144 mn\n",
      "Current vocab size  : 27047\n",
      "ETA : 0.3967176334793227 mn\n",
      "Current vocab size  : 27228\n",
      "ETA : 0.26365461549997327 mn\n",
      "Current vocab size  : 27419\n",
      "ETA : 0.1324869092101521 mn\n",
      "Current vocab size  : 27653\n",
      "ETA : 0.0002659625021616617 mn\n",
      "Current vocab size  : 27928\n",
      "Model saved to the disk\n",
      "3 ieme step on 33\n",
      "ETA : 1.2718995563975968 mn\n",
      "Current vocab size  : 28235\n",
      "ETA : 1.1759226472830775 mn\n",
      "Current vocab size  : 28514\n",
      "ETA : 1.001115055513382 mn\n",
      "Current vocab size  : 28685\n",
      "ETA : 0.8629857366712888 mn\n",
      "Current vocab size  : 28949\n",
      "ETA : 0.7444010314893723 mn\n",
      "Current vocab size  : 29196\n",
      "ETA : 0.5801582230846086 mn\n",
      "Current vocab size  : 29356\n",
      "ETA : 0.43328592612584427 mn\n",
      "Current vocab size  : 29630\n",
      "ETA : 0.28207991239070884 mn\n",
      "Current vocab size  : 29958\n",
      "ETA : 0.13524129816567454 mn\n",
      "Current vocab size  : 30098\n",
      "ETA : 0.0002669233338038126 mn\n",
      "Current vocab size  : 30304\n",
      "Model saved to the disk\n",
      "4 ieme step on 33\n",
      "ETA : 1.1177896698077519 mn\n",
      "Current vocab size  : 30460\n",
      "ETA : 1.040879697175026 mn\n",
      "Current vocab size  : 30701\n",
      "ETA : 0.9205242037325435 mn\n",
      "Current vocab size  : 30844\n",
      "ETA : 0.7735973702263832 mn\n",
      "Current vocab size  : 30974\n",
      "ETA : 0.6479744398593903 mn\n",
      "Current vocab size  : 31112\n",
      "ETA : 0.5272451628796259 mn\n",
      "Current vocab size  : 31278\n",
      "ETA : 0.39632947216510767 mn\n",
      "Current vocab size  : 31452\n",
      "ETA : 0.2582720795202255 mn\n",
      "Current vocab size  : 31634\n",
      "ETA : 0.12780578425036537 mn\n",
      "Current vocab size  : 31783\n",
      "ETA : 0.0002545044350624084 mn\n",
      "Current vocab size  : 31960\n",
      "Model saved to the disk\n",
      "5 ieme step on 33\n",
      "ETA : 1.0797049602413176 mn\n",
      "Current vocab size  : 32103\n",
      "ETA : 0.9852090047931672 mn\n",
      "Current vocab size  : 32254\n",
      "ETA : 0.8643628888130188 mn\n",
      "Current vocab size  : 32414\n",
      "ETA : 0.7500850670456887 mn\n",
      "Current vocab size  : 32591\n",
      "ETA : 0.6162794079613686 mn\n",
      "Current vocab size  : 32781\n",
      "ETA : 0.49159008401420373 mn\n",
      "Current vocab size  : 32936\n",
      "ETA : 0.3685582009493737 mn\n",
      "Current vocab size  : 33129\n",
      "ETA : 0.24449386703968046 mn\n",
      "Current vocab size  : 33306\n",
      "ETA : 0.12430112193195908 mn\n",
      "Current vocab size  : 33482\n",
      "ETA : 0.00025426285187403366 mn\n",
      "Current vocab size  : 33683\n",
      "Model saved to the disk\n",
      "6 ieme step on 33\n",
      "ETA : 1.2671776191926 mn\n",
      "Current vocab size  : 33839\n",
      "ETA : 1.1692411888575556 mn\n",
      "Current vocab size  : 34039\n",
      "ETA : 0.9700835463489428 mn\n",
      "Current vocab size  : 34182\n",
      "ETA : 0.8437765028746922 mn\n",
      "Current vocab size  : 34383\n",
      "ETA : 0.7153606576967239 mn\n",
      "Current vocab size  : 34518\n",
      "ETA : 0.5756557895975641 mn\n",
      "Current vocab size  : 34643\n",
      "ETA : 0.4270240373295829 mn\n",
      "Current vocab size  : 34782\n",
      "ETA : 0.27882924524545666 mn\n",
      "Current vocab size  : 34902\n",
      "ETA : 0.13859780633175814 mn\n",
      "Current vocab size  : 35037\n",
      "ETA : 0.0002749919780095418 mn\n",
      "Current vocab size  : 35214\n",
      "Model saved to the disk\n",
      "7 ieme step on 33\n",
      "ETA : 1.2605756262667975 mn\n",
      "Current vocab size  : 35369\n",
      "ETA : 1.0556455867743495 mn\n",
      "Current vocab size  : 35494\n",
      "ETA : 0.8947504139378337 mn\n",
      "Current vocab size  : 35630\n",
      "ETA : 0.7806798409477871 mn\n",
      "Current vocab size  : 35784\n",
      "ETA : 0.652450598666668 mn\n",
      "Current vocab size  : 35879\n",
      "ETA : 0.5222281366438336 mn\n",
      "Current vocab size  : 36007\n",
      "ETA : 0.3944817671985853 mn\n",
      "Current vocab size  : 36150\n",
      "ETA : 0.26055641473531715 mn\n",
      "Current vocab size  : 36282\n",
      "ETA : 0.13227655645441128 mn\n",
      "Current vocab size  : 36412\n",
      "ETA : 0.0002691143616040548 mn\n",
      "Current vocab size  : 36553\n",
      "Model saved to the disk\n",
      "8 ieme step on 33\n",
      "ETA : 1.3260488018894196 mn\n",
      "Current vocab size  : 36676\n",
      "ETA : 1.150722260129452 mn\n",
      "Current vocab size  : 36834\n",
      "ETA : 0.9968145310240323 mn\n",
      "Current vocab size  : 36933\n",
      "ETA : 0.8224478029799462 mn\n",
      "Current vocab size  : 37047\n",
      "ETA : 0.6805110033011437 mn\n",
      "Current vocab size  : 37173\n",
      "ETA : 0.5422231284705799 mn\n",
      "Current vocab size  : 37273\n",
      "ETA : 0.40119901116530104 mn\n",
      "Current vocab size  : 37359\n",
      "ETA : 0.2687723428630829 mn\n",
      "Current vocab size  : 37502\n",
      "ETA : 0.13581148210746272 mn\n",
      "Current vocab size  : 37621\n",
      "ETA : 0.0002709799464543661 mn\n",
      "Current vocab size  : 37738\n",
      "Model saved to the disk\n",
      "9 ieme step on 33\n",
      "ETA : 1.3195548149800298 mn\n",
      "Current vocab size  : 37829\n",
      "ETA : 1.1322614766526224 mn\n",
      "Current vocab size  : 37966\n",
      "ETA : 0.9906411859668628 mn\n",
      "Current vocab size  : 38078\n",
      "ETA : 0.8631442525148392 mn\n",
      "Current vocab size  : 38249\n",
      "ETA : 0.728718325536251 mn\n",
      "Current vocab size  : 38417\n",
      "ETA : 0.5972839007136557 mn\n",
      "Current vocab size  : 38583\n",
      "ETA : 0.44862445466291334 mn\n",
      "Current vocab size  : 38725\n",
      "ETA : 0.30336507016181946 mn\n",
      "Current vocab size  : 38863\n",
      "ETA : 0.14769820659752245 mn\n",
      "Current vocab size  : 38976\n",
      "ETA : 0.000291552639802297 mn\n",
      "Current vocab size  : 39100\n",
      "Model saved to the disk\n",
      "10 ieme step on 33\n",
      "ETA : 1.1829431547745068 mn\n",
      "Current vocab size  : 39199\n",
      "ETA : 1.0446168409371377 mn\n",
      "Current vocab size  : 39312\n",
      "ETA : 0.8930113232162263 mn\n",
      "Current vocab size  : 39453\n",
      "ETA : 0.795435555100441 mn\n",
      "Current vocab size  : 39595\n",
      "ETA : 0.6826983033013344 mn\n",
      "Current vocab size  : 39702\n",
      "ETA : 0.5369097173322571 mn\n",
      "Current vocab size  : 39865\n",
      "ETA : 0.4091955911931537 mn\n",
      "Current vocab size  : 39993\n",
      "ETA : 0.2738654845190048 mn\n",
      "Current vocab size  : 40093\n",
      "ETA : 0.1393175001079065 mn\n",
      "Current vocab size  : 40187\n",
      "ETA : 0.00027528930425643923 mn\n",
      "Current vocab size  : 40325\n",
      "Model saved to the disk\n",
      "11 ieme step on 33\n",
      "ETA : 1.2932835674492518 mn\n",
      "Current vocab size  : 40471\n",
      "ETA : 1.1119657638382914 mn\n",
      "Current vocab size  : 40592\n",
      "ETA : 0.9568207483704885 mn\n",
      "Current vocab size  : 40708\n",
      "ETA : 0.8380663974801698 mn\n",
      "Current vocab size  : 40872\n",
      "ETA : 0.720150948112011 mn\n",
      "Current vocab size  : 40996\n",
      "ETA : 0.5805773614939054 mn\n",
      "Current vocab size  : 41134\n",
      "ETA : 0.4401060463092441 mn\n",
      "Current vocab size  : 41246\n",
      "ETA : 0.297882018020153 mn\n",
      "Current vocab size  : 41356\n",
      "ETA : 0.1498348490661162 mn\n",
      "Current vocab size  : 41459\n",
      "ETA : 0.00029893956184387206 mn\n",
      "Current vocab size  : 41577\n",
      "Model saved to the disk\n",
      "12 ieme step on 33\n",
      "ETA : 1.6647328164331117 mn\n",
      "Current vocab size  : 41721\n",
      "ETA : 1.4390488088893894 mn\n",
      "Current vocab size  : 41896\n",
      "ETA : 1.1693131065943507 mn\n",
      "Current vocab size  : 42021\n",
      "ETA : 1.023309075741768 mn\n",
      "Current vocab size  : 42149\n",
      "ETA : 0.8403436518645288 mn\n",
      "Current vocab size  : 42260\n",
      "ETA : 0.653332003440857 mn\n",
      "Current vocab size  : 42357\n",
      "ETA : 0.48433518652847835 mn\n",
      "Current vocab size  : 42452\n",
      "ETA : 0.32413229460239407 mn\n",
      "Current vocab size  : 42564\n",
      "ETA : 0.1605463188650873 mn\n",
      "Current vocab size  : 42708\n",
      "ETA : 0.0003210720634460449 mn\n",
      "Current vocab size  : 42843\n",
      "Model saved to the disk\n",
      "13 ieme step on 33\n",
      "ETA : 1.57003721829017 mn\n",
      "Current vocab size  : 42979\n",
      "ETA : 1.2923434441518784 mn\n",
      "Current vocab size  : 43081\n",
      "ETA : 1.0732225372420419 mn\n",
      "Current vocab size  : 43211\n",
      "ETA : 0.8833372788794835 mn\n",
      "Current vocab size  : 43339\n",
      "ETA : 0.7167313140821457 mn\n",
      "Current vocab size  : 43447\n",
      "ETA : 0.5637975634137788 mn\n",
      "Current vocab size  : 43549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA : 0.41687599139769876 mn\n",
      "Current vocab size  : 43676\n",
      "ETA : 0.2763774231934547 mn\n",
      "Current vocab size  : 43785\n",
      "ETA : 0.13811950755499028 mn\n",
      "Current vocab size  : 43886\n",
      "ETA : 0.00027431417465209964 mn\n",
      "Current vocab size  : 44023\n",
      "Model saved to the disk\n",
      "14 ieme step on 33\n",
      "ETA : 1.3594420090587933 mn\n",
      "Current vocab size  : 44149\n",
      "ETA : 1.2198319445872305 mn\n",
      "Current vocab size  : 44259\n",
      "ETA : 1.046340640540388 mn\n",
      "Current vocab size  : 44351\n",
      "ETA : 0.8706704793715476 mn\n",
      "Current vocab size  : 44481\n",
      "ETA : 0.7105013511705399 mn\n",
      "Current vocab size  : 44596\n",
      "ETA : 0.5591439854979515 mn\n",
      "Current vocab size  : 44703\n",
      "ETA : 0.4186719166470709 mn\n",
      "Current vocab size  : 44839\n",
      "ETA : 0.27728651076078414 mn\n",
      "Current vocab size  : 44971\n",
      "ETA : 0.14117368093428787 mn\n",
      "Current vocab size  : 45101\n",
      "ETA : 0.0002822356192270915 mn\n",
      "Current vocab size  : 45219\n",
      "Model saved to the disk\n",
      "15 ieme step on 33\n",
      "ETA : 1.5226033005142212 mn\n",
      "Current vocab size  : 45363\n",
      "ETA : 1.294508281824589 mn\n",
      "Current vocab size  : 45479\n",
      "ETA : 1.086571079214944 mn\n",
      "Current vocab size  : 45580\n",
      "ETA : 0.902123108279705 mn\n",
      "Current vocab size  : 45696\n",
      "ETA : 0.7407945949125291 mn\n",
      "Current vocab size  : 45832\n",
      "ETA : 0.5940290778613091 mn\n",
      "Current vocab size  : 45967\n",
      "ETA : 0.43685740276858925 mn\n",
      "Current vocab size  : 46052\n",
      "ETA : 0.28953644450426097 mn\n",
      "Current vocab size  : 46117\n",
      "ETA : 0.14405112645317006 mn\n",
      "Current vocab size  : 46224\n",
      "ETA : 0.00028818286180496214 mn\n",
      "Current vocab size  : 46314\n",
      "Model saved to the disk\n",
      "16 ieme step on 33\n",
      "ETA : 1.508098307091395 mn\n",
      "Current vocab size  : 46390\n",
      "ETA : 1.2112530880331993 mn\n",
      "Current vocab size  : 46495\n",
      "ETA : 1.0271287003858882 mn\n",
      "Current vocab size  : 46582\n",
      "ETA : 0.8729223808042208 mn\n",
      "Current vocab size  : 46692\n",
      "ETA : 0.7188060739040376 mn\n",
      "Current vocab size  : 46778\n",
      "ETA : 0.5838962454382578 mn\n",
      "Current vocab size  : 46910\n",
      "ETA : 0.42954997293495 mn\n",
      "Current vocab size  : 46988\n",
      "ETA : 0.2858719830751419 mn\n",
      "Current vocab size  : 47091\n",
      "ETA : 0.1419582134659202 mn\n",
      "Current vocab size  : 47165\n",
      "ETA : 0.00028289630969365444 mn\n",
      "Current vocab size  : 47279\n",
      "Model saved to the disk\n",
      "17 ieme step on 33\n",
      "ETA : 1.6336102032955488 mn\n",
      "Current vocab size  : 47404\n",
      "ETA : 1.2771777701854707 mn\n",
      "Current vocab size  : 47477\n",
      "ETA : 1.087972303176986 mn\n",
      "Current vocab size  : 47557\n",
      "ETA : 0.8945760945121446 mn\n",
      "Current vocab size  : 47643\n",
      "ETA : 0.7469938195228577 mn\n",
      "Current vocab size  : 47732\n",
      "ETA : 0.5976558763798078 mn\n",
      "Current vocab size  : 47841\n",
      "ETA : 0.4481876877822194 mn\n",
      "Current vocab size  : 47966\n",
      "ETA : 0.2995163884234428 mn\n",
      "Current vocab size  : 48083\n",
      "ETA : 0.15098641183137892 mn\n",
      "Current vocab size  : 48169\n",
      "ETA : 0.0003026263356208801 mn\n",
      "Current vocab size  : 48254\n",
      "Model saved to the disk\n",
      "18 ieme step on 33\n",
      "ETA : 1.5422456251422565 mn\n",
      "Current vocab size  : 48355\n",
      "ETA : 1.2184772142767908 mn\n",
      "Current vocab size  : 48461\n",
      "ETA : 1.0745251838919851 mn\n",
      "Current vocab size  : 48574\n",
      "ETA : 0.9151086980462074 mn\n",
      "Current vocab size  : 48664\n",
      "ETA : 0.7559739105081559 mn\n",
      "Current vocab size  : 48748\n",
      "ETA : 0.6191217082291178 mn\n",
      "Current vocab size  : 48863\n",
      "ETA : 0.4741108502344858 mn\n",
      "Current vocab size  : 48973\n",
      "ETA : 0.3145348990774154 mn\n",
      "Current vocab size  : 49064\n",
      "ETA : 0.15487732454891553 mn\n",
      "Current vocab size  : 49146\n",
      "ETA : 0.00030637416442235306 mn\n",
      "Current vocab size  : 49224\n",
      "Model saved to the disk\n",
      "19 ieme step on 33\n",
      "ETA : 1.4049484128411611 mn\n",
      "Current vocab size  : 49299\n",
      "ETA : 1.1345026756668093 mn\n",
      "Current vocab size  : 49394\n",
      "ETA : 0.9741253830522962 mn\n",
      "Current vocab size  : 49488\n",
      "ETA : 0.8209853809102376 mn\n",
      "Current vocab size  : 49577\n",
      "ETA : 0.6692498632788658 mn\n",
      "Current vocab size  : 49677\n",
      "ETA : 0.5314075757246548 mn\n",
      "Current vocab size  : 49760\n",
      "ETA : 0.39658897048303055 mn\n",
      "Current vocab size  : 49852\n",
      "ETA : 0.26205733194351194 mn\n",
      "Current vocab size  : 49932\n",
      "ETA : 0.12943705720557108 mn\n",
      "Current vocab size  : 50007\n",
      "ETA : 0.0002560420536994935 mn\n",
      "Current vocab size  : 50093\n",
      "Model saved to the disk\n",
      "20 ieme step on 33\n",
      "ETA : 1.2739142977666855 mn\n",
      "Current vocab size  : 50171\n",
      "ETA : 1.0733399592518809 mn\n",
      "Current vocab size  : 50275\n",
      "ETA : 0.9128512243085439 mn\n",
      "Current vocab size  : 50335\n",
      "ETA : 0.7709491523591678 mn\n",
      "Current vocab size  : 50445\n",
      "ETA : 0.6424276549696923 mn\n",
      "Current vocab size  : 50507\n",
      "ETA : 0.5107538874782456 mn\n",
      "Current vocab size  : 50581\n",
      "ETA : 0.37851792075656704 mn\n",
      "Current vocab size  : 50669\n",
      "ETA : 0.2529613470482826 mn\n",
      "Current vocab size  : 50761\n",
      "ETA : 0.1259772823377009 mn\n",
      "Current vocab size  : 50830\n",
      "ETA : 0.00025081070582071944 mn\n",
      "Current vocab size  : 50899\n",
      "Model saved to the disk\n",
      "21 ieme step on 33\n",
      "ETA : 1.3135679914212226 mn\n",
      "Current vocab size  : 50955\n",
      "ETA : 1.0275797736620904 mn\n",
      "Current vocab size  : 51037\n",
      "ETA : 0.8741723189017508 mn\n",
      "Current vocab size  : 51105\n",
      "ETA : 0.7382518184900284 mn\n",
      "Current vocab size  : 51206\n",
      "ETA : 0.6088729280233384 mn\n",
      "Current vocab size  : 51269\n",
      "ETA : 0.4798282475810581 mn\n",
      "Current vocab size  : 51321\n",
      "ETA : 0.35625431379465833 mn\n",
      "Current vocab size  : 51379\n",
      "ETA : 0.23418819754600523 mn\n",
      "Current vocab size  : 51435\n",
      "ETA : 0.11676639464934667 mn\n",
      "Current vocab size  : 51492\n",
      "ETA : 0.00023729680617650352 mn\n",
      "Current vocab size  : 51550\n",
      "Model saved to the disk\n",
      "22 ieme step on 33\n",
      "ETA : 1.681496744960149 mn\n",
      "Current vocab size  : 51635\n",
      "ETA : 1.249817091434002 mn\n",
      "Current vocab size  : 51672\n",
      "ETA : 1.0337656768610741 mn\n",
      "Current vocab size  : 51746\n",
      "ETA : 0.8684081993865967 mn\n",
      "Current vocab size  : 51815\n",
      "ETA : 0.7206251819944384 mn\n",
      "Current vocab size  : 51910\n",
      "ETA : 0.5798377798302969 mn\n",
      "Current vocab size  : 51976\n",
      "ETA : 0.43416713373297744 mn\n",
      "Current vocab size  : 52059\n",
      "ETA : 0.2828535951375961 mn\n",
      "Current vocab size  : 52140\n",
      "ETA : 0.14176453582039586 mn\n",
      "Current vocab size  : 52228\n",
      "ETA : 0.00028354343652725215 mn\n",
      "Current vocab size  : 52290\n",
      "Model saved to the disk\n",
      "23 ieme step on 33\n",
      "ETA : 1.5274910019199053 mn\n",
      "Current vocab size  : 52347\n",
      "ETA : 1.2205579177737238 mn\n",
      "Current vocab size  : 52421\n",
      "ETA : 1.0346138812677066 mn\n",
      "Current vocab size  : 52504\n",
      "ETA : 0.8574984273783366 mn\n",
      "Current vocab size  : 52560\n",
      "ETA : 0.6910056889081001 mn\n",
      "Current vocab size  : 52630\n",
      "ETA : 0.5465608023937543 mn\n",
      "Current vocab size  : 52690\n",
      "ETA : 0.4070081106906845 mn\n",
      "Current vocab size  : 52742\n",
      "ETA : 0.26871311108350754 mn\n",
      "Current vocab size  : 52815\n",
      "ETA : 0.13340494125878372 mn\n",
      "Current vocab size  : 52861\n",
      "ETA : 0.00026352026065190636 mn\n",
      "Current vocab size  : 52917\n",
      "Model saved to the disk\n",
      "24 ieme step on 33\n",
      "ETA : 1.4583035995308558 mn\n",
      "Current vocab size  : 52967\n",
      "ETA : 1.1436172855544091 mn\n",
      "Current vocab size  : 53029\n",
      "ETA : 0.938249481927289 mn\n",
      "Current vocab size  : 53084\n",
      "ETA : 0.8073522016723952 mn\n",
      "Current vocab size  : 53156\n",
      "ETA : 0.6587045314121248 mn\n",
      "Current vocab size  : 53233\n",
      "ETA : 0.5363345904951626 mn\n",
      "Current vocab size  : 53318\n",
      "ETA : 0.40424390081189926 mn\n",
      "Current vocab size  : 53391\n",
      "ETA : 0.267993032913208 mn\n",
      "Current vocab size  : 53448\n",
      "ETA : 0.13249240315031124 mn\n",
      "Current vocab size  : 53489\n",
      "ETA : 0.0002653727149963379 mn\n",
      "Current vocab size  : 53554\n",
      "Model saved to the disk\n",
      "25 ieme step on 33\n",
      "ETA : 1.453147206336657 mn\n",
      "Current vocab size  : 53630\n",
      "ETA : 1.0909927017641068 mn\n",
      "Current vocab size  : 53701\n",
      "ETA : 0.9033134080497425 mn\n",
      "Current vocab size  : 53779\n",
      "ETA : 0.7427248374128341 mn\n",
      "Current vocab size  : 53851\n",
      "ETA : 0.6045767079091073 mn\n",
      "Current vocab size  : 53901\n",
      "ETA : 0.4751107543171777 mn\n",
      "Current vocab size  : 53956\n",
      "ETA : 0.3588306166797593 mn\n",
      "Current vocab size  : 54007\n",
      "ETA : 0.23998655598878857 mn\n",
      "Current vocab size  : 54094\n",
      "ETA : 0.1205855039884426 mn\n",
      "Current vocab size  : 54153\n",
      "ETA : 0.00023835374116897584 mn\n",
      "Current vocab size  : 54192\n",
      "Model saved to the disk\n",
      "26 ieme step on 33\n",
      "ETA : 1.2268619774063427 mn\n",
      "Current vocab size  : 54236\n",
      "ETA : 1.0052518541145326 mn\n",
      "Current vocab size  : 54269\n",
      "ETA : 0.8591002456776301 mn\n",
      "Current vocab size  : 54317\n",
      "ETA : 0.7391672771437963 mn\n",
      "Current vocab size  : 54375\n",
      "ETA : 0.6092299159932136 mn\n",
      "Current vocab size  : 54429\n",
      "ETA : 0.4952415742082066 mn\n",
      "Current vocab size  : 54502\n",
      "ETA : 0.3580365729879198 mn\n",
      "Current vocab size  : 54531\n",
      "ETA : 0.24148026421308513 mn\n",
      "Current vocab size  : 54587\n",
      "ETA : 0.11722132704090188 mn\n",
      "Current vocab size  : 54624\n",
      "ETA : 0.00023458194176355997 mn\n",
      "Current vocab size  : 54686\n",
      "Model saved to the disk\n",
      "27 ieme step on 33\n",
      "ETA : 1.0149500246278444 mn\n",
      "Current vocab size  : 54710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA : 0.8149463092684748 mn\n",
      "Current vocab size  : 54734\n",
      "ETA : 0.6924858853395781 mn\n",
      "Current vocab size  : 54775\n",
      "ETA : 0.5932777561513584 mn\n",
      "Current vocab size  : 54801\n",
      "ETA : 0.49318615956544887 mn\n",
      "Current vocab size  : 54839\n",
      "ETA : 0.4053635573866633 mn\n",
      "Current vocab size  : 54896\n",
      "ETA : 0.3081214146413122 mn\n",
      "Current vocab size  : 54958\n",
      "ETA : 0.20468112851858136 mn\n",
      "Current vocab size  : 54985\n",
      "ETA : 0.1023344936827377 mn\n",
      "Current vocab size  : 55013\n",
      "ETA : 0.00020500581900278724 mn\n",
      "Current vocab size  : 55058\n",
      "Model saved to the disk\n",
      "28 ieme step on 33\n",
      "ETA : 1.2900175298873582 mn\n",
      "Current vocab size  : 55097\n",
      "ETA : 0.9301318612980843 mn\n",
      "Current vocab size  : 55132\n",
      "ETA : 0.7794240366856258 mn\n",
      "Current vocab size  : 55184\n",
      "ETA : 0.6676717017412186 mn\n",
      "Current vocab size  : 55211\n",
      "ETA : 0.5630428004479409 mn\n",
      "Current vocab size  : 55256\n",
      "ETA : 0.44410922421879245 mn\n",
      "Current vocab size  : 55310\n",
      "ETA : 0.335461861776965 mn\n",
      "Current vocab size  : 55376\n",
      "ETA : 0.2181061296200752 mn\n",
      "Current vocab size  : 55402\n",
      "ETA : 0.10754528737421389 mn\n",
      "Current vocab size  : 55443\n",
      "ETA : 0.00021070836623509725 mn\n",
      "Current vocab size  : 55491\n",
      "Model saved to the disk\n",
      "29 ieme step on 33\n",
      "ETA : 1.2942932091212271 mn\n",
      "Current vocab size  : 55529\n",
      "ETA : 0.9774409708929062 mn\n",
      "Current vocab size  : 55571\n",
      "ETA : 0.8092614353150791 mn\n",
      "Current vocab size  : 55606\n",
      "ETA : 0.6414451239800453 mn\n",
      "Current vocab size  : 55632\n",
      "ETA : 0.5020355551409721 mn\n",
      "Current vocab size  : 55652\n",
      "ETA : 0.3887586758989758 mn\n",
      "Current vocab size  : 55675\n",
      "ETA : 0.2836113302283059 mn\n",
      "Current vocab size  : 55699\n",
      "ETA : 0.18376558850526808 mn\n",
      "Current vocab size  : 55721\n",
      "ETA : 0.09227216248203207 mn\n",
      "Current vocab size  : 55754\n",
      "ETA : 0.00018545824130376183 mn\n",
      "Current vocab size  : 55802\n",
      "Model saved to the disk\n",
      "30 ieme step on 33\n",
      "ETA : 1.2617813596566516 mn\n",
      "Current vocab size  : 55850\n",
      "ETA : 0.9880635742163659 mn\n",
      "Current vocab size  : 55912\n",
      "ETA : 0.8191536885203256 mn\n",
      "Current vocab size  : 55958\n",
      "ETA : 0.7203427532100677 mn\n",
      "Current vocab size  : 56014\n",
      "ETA : 0.5833728243684768 mn\n",
      "Current vocab size  : 56051\n",
      "ETA : 0.47491944550487725 mn\n",
      "Current vocab size  : 56099\n",
      "ETA : 0.3518764478370121 mn\n",
      "Current vocab size  : 56122\n",
      "ETA : 0.2323469608211517 mn\n",
      "Current vocab size  : 56151\n",
      "ETA : 0.1140155813328425 mn\n",
      "Current vocab size  : 56205\n",
      "ETA : 0.00022561310132344562 mn\n",
      "Current vocab size  : 56241\n",
      "Model saved to the disk\n",
      "31 ieme step on 33\n",
      "ETA : 1.1524575267887114 mn\n",
      "Current vocab size  : 56275\n",
      "ETA : 0.8414424867129325 mn\n",
      "Current vocab size  : 56312\n",
      "ETA : 0.6845414126298163 mn\n",
      "Current vocab size  : 56345\n",
      "ETA : 0.5461274864459037 mn\n",
      "Current vocab size  : 56377\n",
      "ETA : 0.4482969205021858 mn\n",
      "Current vocab size  : 56402\n",
      "ETA : 0.360939070177608 mn\n",
      "Current vocab size  : 56424\n",
      "ETA : 0.26545991639080496 mn\n",
      "Current vocab size  : 56449\n",
      "ETA : 0.1814143015050888 mn\n",
      "Current vocab size  : 56487\n",
      "ETA : 0.09089020630933621 mn\n",
      "Current vocab size  : 56533\n",
      "ETA : 0.00018016395966211958 mn\n",
      "Current vocab size  : 56564\n",
      "Model saved to the disk\n",
      "32 ieme step on 33\n",
      "ETA : 1.2350186132240295 mn\n",
      "Current vocab size  : 56604\n",
      "ETA : 0.8457150500059128 mn\n",
      "Current vocab size  : 56627\n",
      "ETA : 0.6861241853825251 mn\n",
      "Current vocab size  : 56644\n",
      "ETA : 0.5695683677800496 mn\n",
      "Current vocab size  : 56688\n",
      "ETA : 0.4660412706327438 mn\n",
      "Current vocab size  : 56722\n",
      "ETA : 0.3673427600285742 mn\n",
      "Current vocab size  : 56757\n",
      "ETA : 0.27160807075125826 mn\n",
      "Current vocab size  : 56806\n",
      "ETA : 0.18049604636907576 mn\n",
      "Current vocab size  : 56849\n",
      "ETA : 0.09045548618599221 mn\n",
      "Current vocab size  : 56878\n",
      "ETA : 0.00017897707859675088 mn\n",
      "Current vocab size  : 56907\n",
      "Model saved to the disk\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(indices)-1):\n",
    "    print(str(i)+\" ieme step on \"+str(len(indices)-1))\n",
    "    model = amazon_word2vec_training(model,'Movies_and_TV_5.json',indices[i+1],indices[i],5000)\n",
    "    #Movies_and_TV_5\n",
    "    #Electronics_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"variables/review_rating/not/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('variables/review_rating/word2vec/model_300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257229853, 347177000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences,total_examples=len(sentences),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of sentences into list of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "6893\n"
     ]
    }
   ],
   "source": [
    "sentences_v,max_len = vectorization(sentences,word2vec_model.wv,word_length=300,max_len=70,adaptable_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting of the data into train and test set (non toke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_vec_train,x_vec_test,y_vec_train,y_vec_test = train_test_split(sentences_v,y,test_size=0.2,random_state=42)\n",
    "x_vec_train=np.array(x_vec_train)\n",
    "x_vec_test=np.array(x_vec_test)\n",
    "from keras.utils import to_categorical\n",
    "y_vec_train=to_categorical(y_vec_train)\n",
    "y_vec_test=to_categorical(y_vec_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting of the data into train and test set (toke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_vec_train,x_vec_test,y_vec_train,y_vec_test = train_test_split(sentences_toke,y,test_size=0.2,random_state=42)\n",
    "x_vec_train=np.array(x_vec_train)\n",
    "x_vec_test=np.array(x_vec_test)\n",
    "from keras.utils import to_categorical\n",
    "y_vec_train=to_categorical(y_vec_train)\n",
    "y_vec_test=to_categorical(y_vec_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Convolution1D,Flatten,MaxPooling1D,Conv1D,LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "# Neural Network\n",
    "def model_creation():\n",
    "    \n",
    "    WORD_LENGTH=300\n",
    "    max_len=70\n",
    "\n",
    "\n",
    "    NN1 = Sequential()\n",
    "    \n",
    "    NN1.add(Dense(max_len,activation='relu',input_shape=(max_len,WORD_LENGTH)))\n",
    "    NN1.add(Dropout(0.5))\n",
    "                   \n",
    "    NN1.add(Convolution1D(64,kernel_size=10,activation='relu',border_mode='causal',input_shape=(max_len,WORD_LENGTH)))\n",
    "    NN1.add(Dropout(0.5))\n",
    "    NN1.add(MaxPooling1D())  \n",
    " \n",
    "    NN1.add(LSTM(50,activation='relu'))\n",
    "    NN1.add(Dropout(0.5))\n",
    "    \n",
    "    NN1.add(Dense(250,activation='relu'))\n",
    "    NN1.add(Dropout(0.5))\n",
    "               \n",
    "    NN1.add(Dense(250, activation='relu'))\n",
    "    NN1.add(Dropout(0.5))\n",
    "        \n",
    "    NN1.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    #learning_rate = 1e-2\n",
    "    #decay_rate = learning_rate / 60\n",
    "    momentum = 0.1\n",
    "    sgd = SGD()\n",
    "    #adam = Adam(lr=learning_rate)\n",
    "    NN1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from keras.layers import Input, Dense,Activation,Convolution1D,Flatten,MaxPooling1D,Conv1D,LSTM,Dropout, Embedding,BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "def model_creation():\n",
    "    \n",
    "    max_len=150\n",
    "    inputs = Input(shape = (max_len,))\n",
    "    emb = word2vec_model.wv.get_keras_embedding(train_embeddings=True)(inputs)\n",
    "    #x = Dropout(0.5)(emb)\n",
    "    x = Dense(max_len, activation='relu')(emb)\n",
    "    x = Dropout(0.5)(x)    \n",
    "    x = Convolution1D(64,kernel_size=10,activation='relu',border_mode='causal')(emb)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = MaxPooling1D(pool_size=2, strides=None, padding='same')(x)\n",
    "    x = LSTM(50)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(250, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(250, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(2,activation = \"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de données de validation : 2349\n",
      "Nombre de données de test : 2348\n"
     ]
    }
   ],
   "source": [
    "x_vec_test,x_vec_valid,y_vec_test,y_vec_valid =  train_test_split(x_vec_test,y_vec_test,test_size=0.5,random_state=42)\n",
    "print(\"Nombre de données de validation : \"+str(len(x_vec_valid)))\n",
    "print(\"Nombre de données de test : \"+str(len(x_vec_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epochs,old_lr):\n",
    "    lr = old_lr\n",
    "    if (epochs<8):\n",
    "        lr = 7e-4\n",
    "    elif (epochs<15):\n",
    "        lr = 3e-4\n",
    "    elif (epochs<30):\n",
    "        lr = 1e-4\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, kernel_size=10, activation=\"relu\", input_shape=(70, 300), padding=\"causal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16909 samples, validate on 1879 samples\n",
      "Epoch 1/15\n",
      "16909/16909 [==============================] - 5s 318us/step - loss: 0.9773 - acc: 0.7737 - val_loss: 0.6954 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69536, saving model to weights.hdf5\n",
      "Epoch 2/15\n",
      "16909/16909 [==============================] - 3s 197us/step - loss: 0.7161 - acc: 0.7738 - val_loss: 0.6954 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69536 to 0.69536, saving model to weights.hdf5\n",
      "Epoch 3/15\n",
      "16909/16909 [==============================] - 3s 195us/step - loss: 0.7002 - acc: 0.7738 - val_loss: 0.6896 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69536 to 0.68956, saving model to weights.hdf5\n",
      "Epoch 4/15\n",
      "16909/16909 [==============================] - 3s 196us/step - loss: 0.6981 - acc: 0.7738 - val_loss: 0.6892 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68956 to 0.68922, saving model to weights.hdf5\n",
      "Epoch 5/15\n",
      "16909/16909 [==============================] - 3s 195us/step - loss: 0.6963 - acc: 0.7738 - val_loss: 0.6867 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68922 to 0.68665, saving model to weights.hdf5\n",
      "Epoch 6/15\n",
      "16909/16909 [==============================] - 3s 201us/step - loss: 0.6968 - acc: 0.7738 - val_loss: 0.6862 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68665 to 0.68619, saving model to weights.hdf5\n",
      "Epoch 7/15\n",
      "16909/16909 [==============================] - 4s 210us/step - loss: 0.6969 - acc: 0.7738 - val_loss: 0.6875 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.68619\n",
      "Epoch 8/15\n",
      "16909/16909 [==============================] - 4s 215us/step - loss: 0.6952 - acc: 0.7738 - val_loss: 0.6865 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.68619\n",
      "Epoch 9/15\n",
      "16909/16909 [==============================] - 3s 204us/step - loss: 0.6961 - acc: 0.7738 - val_loss: 0.6868 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68619\n",
      "Epoch 10/15\n",
      "16909/16909 [==============================] - 3s 199us/step - loss: 0.6957 - acc: 0.7738 - val_loss: 0.6871 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.68619\n",
      "Epoch 11/15\n",
      "16909/16909 [==============================] - 3s 203us/step - loss: 0.6965 - acc: 0.7738 - val_loss: 0.6861 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.68619 to 0.68609, saving model to weights.hdf5\n",
      "Epoch 12/15\n",
      "16909/16909 [==============================] - 3s 198us/step - loss: 0.6952 - acc: 0.7738 - val_loss: 0.6861 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.68609\n",
      "Epoch 13/15\n",
      "16909/16909 [==============================] - 3s 205us/step - loss: 0.6949 - acc: 0.7738 - val_loss: 0.6863 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.68609\n",
      "Epoch 14/15\n",
      "16909/16909 [==============================] - 3s 199us/step - loss: 0.6961 - acc: 0.7738 - val_loss: 0.6868 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.68609\n",
      "Epoch 15/15\n",
      "16909/16909 [==============================] - 3s 206us/step - loss: 0.6961 - acc: 0.7738 - val_loss: 0.6882 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.68609\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import clone_model\n",
    "import time \n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "NN = model_creation()\n",
    "#validation_data=(x_vec_valid,y_vec_valid)\n",
    "#,callbacks=[LearningRateScheduler(schedule, verbose=0)]\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "hist_300_4 = NN.fit(x_vec_train, y_vec_train, epochs=15,batch_size =1028,callbacks=[checkpointer],validation_split=0.1)\n",
    "NN.load_weights('weights.hdf5')\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "plt.plot(hist_300_4.history[\"val_acc\"],'r*-')\n",
    "plt.plot(hist_300_4.history[\"acc\"],'b*-')\n",
    "plt.legend((\"Validation accuracy with schedule\",\"Training accuracy with schedule\"))\n",
    "plt.savefig(\"documents/Acc_google_new2\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, kernel_size=10, activation=\"relu\", padding=\"causal\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16909 samples, validate on 1879 samples\n",
      "Epoch 1/30\n",
      "16909/16909 [==============================] - 8s 482us/step - loss: 0.3660 - acc: 0.8413 - val_loss: 0.3489 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34889, saving model to weights.hdf5\n",
      "Epoch 2/30\n",
      "16909/16909 [==============================] - 4s 244us/step - loss: 0.3432 - acc: 0.8456 - val_loss: 0.3539 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34889\n",
      "Epoch 3/30\n",
      "16909/16909 [==============================] - 4s 253us/step - loss: 0.3402 - acc: 0.8460 - val_loss: 0.3622 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34889\n",
      "Epoch 4/30\n",
      "16909/16909 [==============================] - 4s 242us/step - loss: 0.3388 - acc: 0.8461 - val_loss: 0.3581 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34889\n",
      "Epoch 5/30\n",
      "16909/16909 [==============================] - 4s 232us/step - loss: 0.3372 - acc: 0.8474 - val_loss: 0.3628 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34889\n",
      "Epoch 6/30\n",
      "16909/16909 [==============================] - 4s 223us/step - loss: 0.3358 - acc: 0.8482 - val_loss: 0.3617 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34889\n",
      "Epoch 7/30\n",
      "16909/16909 [==============================] - 4s 224us/step - loss: 0.3361 - acc: 0.8476 - val_loss: 0.3592 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34889\n",
      "Epoch 8/30\n",
      "16909/16909 [==============================] - 4s 220us/step - loss: 0.3352 - acc: 0.8489 - val_loss: 0.3570 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34889\n",
      "Epoch 9/30\n",
      "16909/16909 [==============================] - 4s 222us/step - loss: 0.3350 - acc: 0.8487 - val_loss: 0.3550 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34889\n",
      "Epoch 10/30\n",
      "16909/16909 [==============================] - 4s 246us/step - loss: 0.3345 - acc: 0.8484 - val_loss: 0.3550 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34889\n",
      "Epoch 11/30\n",
      "16909/16909 [==============================] - 4s 246us/step - loss: 0.3347 - acc: 0.8492 - val_loss: 0.3563 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34889\n",
      "Epoch 12/30\n",
      "16909/16909 [==============================] - 4s 261us/step - loss: 0.3337 - acc: 0.8497 - val_loss: 0.3564 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34889\n",
      "Epoch 13/30\n",
      "16909/16909 [==============================] - 4s 241us/step - loss: 0.3334 - acc: 0.8484 - val_loss: 0.3548 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34889\n",
      "Epoch 14/30\n",
      "16909/16909 [==============================] - 4s 246us/step - loss: 0.3327 - acc: 0.8506 - val_loss: 0.3551 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34889\n",
      "Epoch 15/30\n",
      "16909/16909 [==============================] - 4s 234us/step - loss: 0.3331 - acc: 0.8492 - val_loss: 0.3524 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34889\n",
      "Epoch 16/30\n",
      "16909/16909 [==============================] - 4s 238us/step - loss: 0.3332 - acc: 0.8505 - val_loss: 0.3545 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34889\n",
      "Epoch 17/30\n",
      "16909/16909 [==============================] - 4s 248us/step - loss: 0.3326 - acc: 0.8500 - val_loss: 0.3507 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34889\n",
      "Epoch 18/30\n",
      "16909/16909 [==============================] - 4s 256us/step - loss: 0.3330 - acc: 0.8491 - val_loss: 0.3484 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34889 to 0.34837, saving model to weights.hdf5\n",
      "Epoch 19/30\n",
      "16909/16909 [==============================] - 4s 239us/step - loss: 0.3328 - acc: 0.8487 - val_loss: 0.3470 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34837 to 0.34697, saving model to weights.hdf5\n",
      "Epoch 20/30\n",
      "16909/16909 [==============================] - 4s 231us/step - loss: 0.3327 - acc: 0.8499 - val_loss: 0.3481 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34697\n",
      "Epoch 21/30\n",
      "16909/16909 [==============================] - 4s 236us/step - loss: 0.3326 - acc: 0.8502 - val_loss: 0.3466 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.34697 to 0.34660, saving model to weights.hdf5\n",
      "Epoch 22/30\n",
      "16909/16909 [==============================] - 4s 235us/step - loss: 0.3322 - acc: 0.8503 - val_loss: 0.3447 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.34660 to 0.34474, saving model to weights.hdf5\n",
      "Epoch 23/30\n",
      "16909/16909 [==============================] - 4s 236us/step - loss: 0.3324 - acc: 0.8497 - val_loss: 0.3437 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34474 to 0.34365, saving model to weights.hdf5\n",
      "Epoch 24/30\n",
      "16909/16909 [==============================] - 4s 235us/step - loss: 0.3329 - acc: 0.8494 - val_loss: 0.3454 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34365\n",
      "Epoch 25/30\n",
      "16909/16909 [==============================] - 4s 227us/step - loss: 0.3324 - acc: 0.8498 - val_loss: 0.3449 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34365\n",
      "Epoch 26/30\n",
      "16909/16909 [==============================] - 4s 224us/step - loss: 0.3318 - acc: 0.8510 - val_loss: 0.3461 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34365\n",
      "Epoch 27/30\n",
      "16909/16909 [==============================] - 4s 232us/step - loss: 0.3324 - acc: 0.8499 - val_loss: 0.3445 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34365\n",
      "Epoch 28/30\n",
      "16909/16909 [==============================] - 4s 226us/step - loss: 0.3323 - acc: 0.8489 - val_loss: 0.3442 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34365\n",
      "Epoch 29/30\n",
      "16909/16909 [==============================] - 4s 225us/step - loss: 0.3324 - acc: 0.8501 - val_loss: 0.3426 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34365 to 0.34262, saving model to weights.hdf5\n",
      "Epoch 30/30\n",
      "16909/16909 [==============================] - 4s 225us/step - loss: 0.3322 - acc: 0.8505 - val_loss: 0.3417 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34262 to 0.34172, saving model to weights.hdf5\n",
      "The training took 2.2575427254041034 mn\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "start_time = time.time()\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0,patience=0,verbose=0, mode='auto')\n",
    "\n",
    "NN = model_creation()\n",
    "\n",
    "hist_google = NN.fit(x_vec_train, y_vec_train, epochs=30, batch_size=1028,validation_split=0.1,callbacks=[checkpointer])\n",
    "NN.load_weights('weights.hdf5')\n",
    "\n",
    "print(\"The training took \"+str((time.time()-start_time)/60)+\" mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4697/4697 [==============================] - 5s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34040658617872416, 0.83333331314787]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.evaluate(x_vec_test,y_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[374 126]\n",
      " [  8 492]]\n",
      "Accuracy and loss for the amazon dataset : 0.866\n",
      "\n",
      "Confusion matrix : \n",
      " [[268 232]\n",
      " [ 15 485]]\n",
      "Accuracy and loss for the yelp dataset : 0.753\n",
      "\n",
      "Confusion matrix : \n",
      " [[371 129]\n",
      " [ 22 478]]\n",
      "Accuracy and loss for the movies dataset : 0.849\n",
      "\n",
      "Mean for the 3 datasets = 0.8226666666666667\n",
      "\n",
      "Confusion matrix :\n",
      " [[ 1372   577]\n",
      " [  636 13906]]\n",
      "Evaluation on the test set : 0.9264447274270814\n"
     ]
    }
   ],
   "source": [
    "protocol_test_embedding_gensim(NN_test,word2vec_model,150,x_vec_train,y_vec_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Word2vec part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time        \n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "def transform_x_y(x,y):\n",
    "    x_good = []\n",
    "    y_good = []\n",
    "    for i in range(len(x)):\n",
    "        if y[i] != 3:\n",
    "            x_good.append(x[i])\n",
    "            y_good.append(y[i])\n",
    "    return x_good,y_good\n",
    "\n",
    "\n",
    "def transform(y):\n",
    "    if(y>3):\n",
    "        return 1\n",
    "    if(y<3):\n",
    "        return 0\n",
    "\n",
    "def my_generator():\n",
    "\n",
    "    \n",
    "    with open(dataset_path+'Electronics_5.json', 'r') as jsonfile:\n",
    "        x = []\n",
    "        WORD_LENGTH =300\n",
    "        max_len = 70\n",
    "        y=[]\n",
    "        i = 0\n",
    "        j = 1\n",
    "        while(1):\n",
    "            for line in jsonfile :\n",
    "                tmp = json.loads(line)\n",
    "                x.append(tmp['reviewText'])\n",
    "                y.append(int(tmp['overall']))\n",
    "                if(j%2000 == 0):\n",
    "                    sentences= []\n",
    "                    x,y = transform_x_y(x,y)\n",
    "                    for i in range(len(x)):\n",
    "                        sentences.append(text_to_word_sequence(x[i]))\n",
    "        \n",
    "                    sentences_v,max_len = vectorization(sentences,word2vec_model,word_length=WORD_LENGTH,max_len=max_len)\n",
    "                    x_train = []\n",
    "                    y_train = []\n",
    "                    \n",
    "                    for k in range(len(sentences_v)):\n",
    "                        if(len(sentences_v[k])==max_len):\n",
    "                            x_train.append(sentences_v[k])\n",
    "                            y_train.append(transform(y[k]))\n",
    "                    x_train = np.array(x_train)\n",
    "                    y_train = to_categorical(y_train)\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    \n",
    "\n",
    "                    yield (x_train,y_train)\n",
    "                i+=1\n",
    "                j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time        \n",
    "from keras.utils import to_categorical\n",
    "import numpy as np \n",
    "\n",
    "def transform_x_y(x,y):\n",
    "    x_good = []\n",
    "    y_good = []\n",
    "    for i in range(len(x)):\n",
    "        if y[i] != 3:\n",
    "            x_good.append(x[i])\n",
    "            y_good.append(y[i])\n",
    "    return x_good,y_good\n",
    "\n",
    "def transform(y):\n",
    "    if(y>3):\n",
    "        return 1\n",
    "    if(y<3):\n",
    "        return 0\n",
    "\n",
    "def my_generator(dataset='Movies_and_TV_5.json'):\n",
    "\n",
    "    \n",
    "    with open(dataset_path+dataset, 'r') as jsonfile:\n",
    "        x = []\n",
    "        y = []\n",
    "        i = 0\n",
    "        j = 1\n",
    "        max_len = 150\n",
    "        while(1):\n",
    "            for line in jsonfile :\n",
    "                tmp = json.loads(line)\n",
    "                x.append(tmp['reviewText'])\n",
    "                y.append(int(tmp['overall']))\n",
    "                if(j%2000 == 0):\n",
    "                    # Sentences pretreatment and not propagation\n",
    "                    sentences= []\n",
    "                    x,y = transform_x_y(x,y)\n",
    "                    \n",
    "                    for i in range(len(x)):\n",
    "                        if \"not\" in x[i]:\n",
    "                            x[i]= treatment_negation(x[i])\n",
    "                        sentences.append(text_to_word_sequence(x[i]))\n",
    "                    \n",
    "                    sentences_toke = tokenize(word2vec_model,sentences,max_len)\n",
    "                    \n",
    "                    x_train = []\n",
    "                    y_train = []\n",
    "                    for k in range(len(sentences_toke)):\n",
    "                        if(len(sentences_toke[k])==max_len):\n",
    "                            x_train.append(sentences_toke[k])\n",
    "                            y_train.append(transform(y[k]))\n",
    "\n",
    "                    x_train = np.array(x_train)\n",
    "                    y_train = to_categorical(y_train)\n",
    "\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    yield x_train,y_train\n",
    "                i+=1\n",
    "                j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, kernel_size=10, activation=\"relu\", padding=\"causal\")`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "NN = model_creation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Word2Vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.1671 - acc: 0.9375 - val_loss: 0.2136 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21362, saving model to weights_books.hdf5\n",
      "Epoch 2/7\n",
      "100/100 [==============================] - 49s 489ms/step - loss: 0.1372 - acc: 0.9498 - val_loss: 0.2028 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21362 to 0.20281, saving model to weights_books.hdf5\n",
      "Epoch 3/7\n",
      "100/100 [==============================] - 49s 491ms/step - loss: 0.1368 - acc: 0.9499 - val_loss: 0.2372 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20281\n",
      "Epoch 4/7\n",
      "100/100 [==============================] - 51s 507ms/step - loss: 0.1379 - acc: 0.9495 - val_loss: 0.2171 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20281\n",
      "Epoch 5/7\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 0.1508 - acc: 0.9439 - val_loss: 0.2197 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20281\n",
      "Epoch 6/7\n",
      "100/100 [==============================] - 48s 481ms/step - loss: 0.1306 - acc: 0.9521 - val_loss: 0.2224 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20281\n",
      "Epoch 7/7\n",
      "100/100 [==============================] - 48s 483ms/step - loss: 0.1375 - acc: 0.9476 - val_loss: 0.2277 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20281\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights_books.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "#'Electronics_5.json'\n",
    "#'Movies_and_TV_5.json'\n",
    "validation_data=(x_vec_test,y_vec_test)\n",
    "hist =NN.fit_generator(my_generator('Books_5.json'),steps_per_epoch=100,epochs=7,validation_data=validation_data,callbacks=[checkpointer])\n",
    "NN.load_weights('weights_books.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Word2Vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:135: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 90s 901ms/step - loss: 0.2439 - acc: 0.9052\n",
      "Epoch 2/7\n",
      "100/100 [==============================] - 90s 903ms/step - loss: 0.2243 - acc: 0.9122\n",
      "Epoch 3/7\n",
      "100/100 [==============================] - 91s 907ms/step - loss: 0.2216 - acc: 0.9135\n",
      "Epoch 4/7\n",
      "100/100 [==============================] - 93s 933ms/step - loss: 0.2177 - acc: 0.9153\n",
      "Epoch 5/7\n",
      "100/100 [==============================] - 91s 915ms/step - loss: 0.2117 - acc: 0.9176\n",
      "Epoch 6/7\n",
      "100/100 [==============================] - 89s 893ms/step - loss: 0.2039 - acc: 0.9213\n",
      "Epoch 7/7\n",
      "100/100 [==============================] - 90s 896ms/step - loss: 0.1910 - acc: 0.9271\n"
     ]
    }
   ],
   "source": [
    "#'Electronics_5.json'\n",
    "#'Movies_and_TV_5.json'\n",
    "#validation_data=(x_vec_test,y_vec_test)\n",
    "hist =NN.fit_generator(my_generator(),steps_per_epoch=100,epochs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:135: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[110 390]\n",
      " [  1 499]]\n",
      "Accuracy and loss for the amazon dataset : 0.609\n",
      "\n",
      "Confusion matrix : \n",
      " [[ 63 437]\n",
      " [  5 495]]\n",
      "Accuracy and loss for the yelp dataset : 0.558\n",
      "\n",
      "Confusion matrix : \n",
      " [[ 79 421]\n",
      " [  3 497]]\n",
      "Accuracy and loss for the movies dataset : 0.576\n",
      "\n",
      "Mean for the 3 datasets = 0.581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protocol_test(NN,word2vec_model,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[337 163]\n",
      " [  9 491]]\n",
      "Accuracy and loss for the amazon dataset : 0.828\n",
      "\n",
      "Confusion matrix : \n",
      " [[222 278]\n",
      " [ 10 490]]\n",
      "Accuracy and loss for the yelp dataset : 0.712\n",
      "\n",
      "Confusion matrix : \n",
      " [[324 176]\n",
      " [ 19 481]]\n",
      "Accuracy and loss for the movies dataset : 0.805\n",
      "\n",
      "Mean for the 3 datasets = 0.7816666666666667\n",
      "\n",
      "Confusion matrix :\n",
      " [[ 1198   751]\n",
      " [  439 14103]]\n",
      "Evaluation on the test set : 0.9278394275665515\n"
     ]
    }
   ],
   "source": [
    "protocol_test_embedding_gensim(NN,word2vec_model,150,x_vec_train,y_vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[328 172]\n",
      " [  6 494]]\n",
      "Accuracy and loss for the amazon dataset : 0.822\n",
      "\n",
      "Confusion matrix : \n",
      " [[225 275]\n",
      " [  6 494]]\n",
      "Accuracy and loss for the yelp dataset : 0.719\n",
      "\n",
      "Confusion matrix : \n",
      " [[328 172]\n",
      " [  9 491]]\n",
      "Accuracy and loss for the movies dataset : 0.819\n",
      "\n",
      "Mean for the 3 datasets = 0.7866666666666666\n",
      "\n",
      "Confusion matrix :\n",
      " [[ 1209   740]\n",
      " [  454 14088]]\n",
      "Evaluation on the test set : 0.9275968710205567\n"
     ]
    }
   ],
   "source": [
    "protocol_test_embedding_gensim(NN,word2vec_model,150,x_vec_train,y_vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[290 210]\n",
      " [  6 494]]\n",
      "Accuracy and loss for the amazon dataset : 0.784\n",
      "\n",
      "Confusion matrix : \n",
      " [[225 275]\n",
      " [  4 496]]\n",
      "Accuracy and loss for the yelp dataset : 0.721\n",
      "\n",
      "Confusion matrix : \n",
      " [[342 158]\n",
      " [ 14 486]]\n",
      "Accuracy and loss for the movies dataset : 0.828\n",
      "\n",
      "Mean for the 3 datasets = 0.7776666666666666\n",
      "\n",
      "Confusion matrix :\n",
      " [[ 1174   775]\n",
      " [  538 14004]]\n",
      "Evaluation on the test set : 0.9203808137772118\n"
     ]
    }
   ],
   "source": [
    "protocol_test_embedding_gensim(NN,word2vec_model,150,x_vec_train,y_vec_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_acc_loss_val (history,path=\"\"):\n",
    "\n",
    "    plt.figure(figsize=(13,8))\n",
    "    plt.plot(history.history[\"val_acc\"],'r-')\n",
    "    plt.plot(history.history[\"acc\"],'b-')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend((\"Validation accuracy\",\"Training accuracy\"))\n",
    "    \n",
    "    if (path != \"\"):\n",
    "        plt.savefig(path+\"_acc\")\n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "    plt.figure(figsize=(13,8))\n",
    "    plt.plot(history.history[\"val_loss\"],'r-')\n",
    "    plt.plot(history.history[\"loss\"],'b-')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend((\"Validation loss\",\"Training loss\"))\n",
    "    if (path != \"\"):\n",
    "        plt.savefig(path+\"_loss\")\n",
    "\n",
    "    plt.show() \n",
    "\n",
    "\n",
    "def plot_acc_loss(history,path=\"\"):\n",
    "\n",
    "    plt.figure(figsize=(13,8))\n",
    "    plt.plot(history.history[\"acc\"],'b-')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(\"Training accuracy\")\n",
    "    \n",
    "    if (path != \"\"):\n",
    "        plt.savefig(path+\"_acc\")\n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "    plt.figure(figsize=(13,8))\n",
    "    plt.plot(history.history[\"loss\"],'b-')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(\"Training loss\")\n",
    "    if (path != \"\"):\n",
    "        plt.savefig(path+\"_loss\")\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxIAAAHjCAYAAAC3lSleAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XeY1NWh//H3oStiCWBFA1E0ItjY2GKJxl7AhmKKMble41WvGjVBsYNgS0xMYoqJJkZ/MxQrdo3tGqLiqliwIjasCCqC0s/vj7PGVYHdhZ09M7Pv1/Psszuz35n5bIA4nz0txBiRJEmSpKZokzuAJEmSpMpjkZAkSZLUZBYJSZIkSU1mkZAkSZLUZBYJSZIkSU1mkZAkSZLUZBYJSZIkSU1mkZAkSZLUZBYJSZIkSU3WLneA5tKtW7fYs2fP3DEkSZKkivbYY4+9H2Ps3tB1VVMkevbsSW1tbe4YkiRJUkULIbzWmOuc2iRJkiSpySwSkiRJkprMIiFJkiSpyapmjYQkSZJULubPn8/UqVOZM2dO7ihL1KlTJ3r06EH79u2X6fEWCUmSJKmZTZ06lS5dutCzZ09CCLnjfEWMkenTpzN16lR69eq1TM/h1CZJkiSpmc2ZM4euXbuWZYkACCHQtWvX5RoxsUhIkiRJJVCuJeIzy5vPIiFJkiSpyVwjIUmSJFWZ6dOn893vfheAd955h7Zt29K9ezqsesKECXTo0GG5X8MiIUmSJFWZrl27MnHiRADOOeccVlppJU455ZRmfQ2LhCRJklRCJ54Ide/pm83mm8NvftO8z9lUrpGQJEmS1GSOSEiSJEkllHvkoFQckZAkSZLUZBYJSZIkSU1mkZAkSZLUZK6RkCS1iEWL0uc2/gpLklrUOeecU5Ln9f/OJUklN2lS2qpw/fXh2mshxtyJJEnLyyIhSSqZGOGvf4VvfQvefRdWWgkGDYLvfheeeip3OknS8rBISJJKYuZM+N734L//G7bbDp58Ep54Av7wh/T1FlvAMcfA9Om5k0pSacQyH35d3nwWCUlSs6uthS23hLFjYcQIuPNOWHNNaNcO/ud/4KWX4Nhj4fLLoXdv+N3vYMGC3Kklqfl06tSJ6dOnl22ZiDEyffp0OnXqtMzPEcr1h2uqmpqaWFtbmzuGJLVqMcKll8IvfpGKQ6EA22+/5OufeQZOPBHuuQc22SQd2rTrri2XV5JKZf78+UydOpU5c+bkjrJEnTp1okePHrRv3/4L94cQHosx1jT0eHdtkiQ1i/ffhx//GG65BQYMgL/9Db72taU/pm9fuPtuuOkmOPlk2G032H9/+NWv4BvfaJncklQK7du3p1evXrljlJRTmyRJy+3//i/tynTXXWlE4sYbGy4RnwkhlYdJk2DkyFQsNt4Yhg6FWbNKm1uStOwsEpKkZbZwIQwbBjvvDCusAA89BMcfn8pBU3XqBKedBi++CIceCuefDxtuCFdf/fkZFJKk8mGRkCQtk7feSlORzj4bBg+Gxx9PC6yX19prwz/+kUpJjx5w+OHw7W/DhAnL/9ySpOZjkZAkNdkdd6SpTI88AldeCddcA126NO9rbLMNPPxwWmvxyiuw9dZpDcbbbzfv60iSlk1Ji0QIYc8QwgshhMkhhFOXct3BIYQYQqj50v3rhRBmhRBOKWVOSVLjzJ+fdmTaa6+0K1NtbXpzvyxTmRqjTRs44og03WnIkLQL1IYbwkUXwdy5pXlNSVLjlKxIhBDaApcBewF9gMNCCH0Wc10X4HjgkcU8za+B20uVUZLUeK+8AjvsABdfDEcfnUYjNt64ZV575ZXhggvSguxddkmlom9fuPnmtOWsJKnllXJEYitgcoxxSoxxHjAKGLiY64YDFwFf2GQ3hLA/MAWYVMKMkqRGuPbadBL1c8/BmDHwxz+mxdUtbYMN0laxd9wB7dunbWb33DPlkiS1rFIWiXWAN+rdnlp333+EELYA1o0x3vKl+zsDQ4Bzl/YCIYSjQgi1IYTaadOmNU9qSdJ/fPppOol60CDYaCOYODF9ndsee8CTT6YD7B55BPr1Swfbffhh7mSS1HqUskgsbsbsfwagQwhtSFOXTl7MdecCv44xLnUH8Rjj5THGmhhjTffu3ZcrrCTpi557Li1w/tOf4JRT4MEHoZzOVmrfHk44AV56CY48En77W+jdGy6/PG1LK0kqrVIWianAuvVu9wDeqne7C9AXuD+E8CqwDTCubsH11sBFdfefCAwNIRxXwqySpDoxpp2SamrSDkm33ZbWRXTokDvZ4nXvnsrO449Dnz7w05+m7P/3f7mTSVJ1K2WReBToHULoFULoAAwGxn32zRjjRzHGbjHGnjHGnsDDwIAYY22McYd69/8GGBlj/H0Js0qSgI8/hh/+EH7yE9hqqzR9aK+9cqdqnM03h/vvh9GjYfp02GmndLDd66/nTiZJ1alkRSLGuAA4DrgTeA4YE2OcFEIYFkIYUKrXlSQtmyeegP79oVhMp1X/85/pcLhKEgIccgg8/zycc07a1WmjjdLXn3ySO50kVZcQq2TfvJqamlhbW5s7hiRVnBjh979P6yC6d09nNey4Y+5UzeP119O5F6NHw7rrpilahxxSunMvJKkahBAeizHWNHSdJ1tLUis2YwYccAAcfzzsvnvalalaSgTAeuvBqFHwwAPQtSsMHpymPD3xRO5kklT5LBKS1EqNH5/WFdx2G1xyCYwbB9265U5VGjvumE7h/vOf025U/funRdnuHC5Jy84iIUmtzKJFMHJk+s18+/bw73/Dz35W/dN92raFo45K28WecAJceWXaLvY3v4H583Onk6TKY5GQpFbknXfSYW6nnw4HH5y2TK1pcBZsdVl1Vfj1r+Gpp2CbbVKJ2nRTuPPO3MkkqbJYJCSplbjrLthsszSl6S9/SbszrbJK7lT5bLwx3H572tlpwQLYc08YMCCNWEiSGmaRkKQqN38+nHZaGono1g0efTSdBF3tU5kaIwTYd1945hm48EK47z7YZBMYMgRmzsydTpLKm0VCkqrYa6+ltRAXXJDKw6OPpjfK+qKOHdM2sS+9BD/4AVx0UTp/4u9/T2tKJElfZZGQpCp1ww1pV6ZnnknTmP7yF1hxxdypytuaa6ZF2BMmQM+e8OMfp3UUDz+cO5kklR+LhCRVmTlz4Ljj4MADYYMN0pkJgwfnTlVZvvWttJbk6qvhzTdh223hhz+Et97KnUySyodFQpKqyIsvpje9l12WdiMaPx7WXz93qsrUpk2a5vTCCzB0KIwZAxtumLbOnTMndzpJys8iIUlV4uqrYcst4Y030k5El1wCHTrkTlX5VloJRoxIB9nttlvaOneTTeDGGyHG3OkkKR+LhCRVuFmz4Igj4PDD04nNEyemnYjUvL7xjbTu5O67YYUV4IADUrF45pncySQpD4uEJFWwJ59MB8r94x9w1llwzz3Qo0fuVNVt111TWfvd79KBfptvDv/7vzBjRu5kktSyLBKSVIFihD/8AbbeOp13cM89cO650K5d7mStQ7t2aUH7Sy/BT3+a/ix6906fFyzInU6SWoZFQpIqzAcfwMEHw7HHws47p9+O77xz7lStU9euaWH7E0/AppumP5Mtt0wH20lStbNISFIFeegh2GILGDcOLr4Ybr0VVl89dyptuincey9ce20aIdpll1T2Xn01dzJJKh2LhCRVgEWL4MILYYcdIAT417/glFPSFqUqDyHAQQel3Z2GD4fbb4dvfhPOPBNmz86dTpKan/8JkqQy9957sPfecOqp6ZC5J55IayNUnlZYAc44I50/cdBBcN55sNFGUCi4Xayk6mKRkKQyds89sNlm8MAD8Kc/wejRsOqquVOpMXr0gP/3/9Lo0Zprwve/D9tvD489ljuZJDUPi4QklaEFC9JvtXfbLRWHCRPS7kAh5E6mpvr2t9Of3xVXwOTJ8K1vwZFHwrvv5k4mScvHIiFJZeaNN9IuTCNGpIPmamuhX7/cqbQ82rSBn/wEXnwRTjoJrroKNtwQfvUrmDcvdzpJWjYWCUkqI+PGpQPOJk6Ea66BK6+Ezp1zp1JzWWUV+OUv02nYO+yQFsz36we33ZY7mSQ1nUVCksrA3Llw4okwcCB8/evpxOTvfz93KpXKRhvBLbd8XiD22SctqH/hhby5JKkpLBKSlNlLL8F228Gll8Lxx6ezInr3zp1KLWGvveDpp9MUp/HjoW9fOPlk+Oij3MkkqWEWCUnKqFBIJyG/8grcdFMqEx075k6lltShQ1o38eKLaU3Mr3+d1k9ccQUsXJg7nSQtmUVCkjKYPRv+67/S9KXNNoMnn4QBA3KnUk5rrAF/+Qs8+mgakTrySNhqqzRSIUnlyCIhSS3s6afTFqB/+xucfjrcfz+su27uVCoX/fvDgw+m0ar33ktnT3zvezB1au5kkvRFFglJaiExwp//nH7LPGMG3HVXOvW4XbvcyVRuQoDDDoPnn4czz4QbbkgLtIcPh08/zZ1OkhKLhCS1gI8+gkMPhaOPhh13TFOZdt01dyqVu86dYdgweO65tKvTWWfBxhvDtdemYipJOVkkJKnEJkyALbaA66+HCy6A229P8+GlxurZE8aOhXvvhZVXhkGDYJdd4KmncieT1JpZJCSpRBYtStt6fvvbafedBx+EIUPSKcfSsth553TGyB/+kErEFlvAMcfA9Om5k0lqjfzPmSSVwLRpsN9+6eTi/fZLJ1Vvu23uVKoG7drB//xPOn/k2GPh8svTLk+/+x3Mn587naTWxCIhSc3s/vth883hnnvgssvguutgtdVyp1K1+drX4Le/Tett+vdPhxluvjn885+5k0lqLSwSktRMFi6Es89Oc9dXWgkefjhNOwkhdzJVs002STuA3XgjzJkDu+0G++8PL7+cO5mkameRkKRm8OabqUAMGwY//CE89lj67bDUEkKAgQNh0iQYOTKNSvTpA0OHwqxZudNJqlYWCUlaTrfemk6nfuwxuOqq9LHSSrlTqTXq1AlOOw1efDFtN3z++bDhhnD11WnxvyQ1J4uEJC2jefPg5JNh332hR49UJA4/PHcqCdZeG/7xD3joofR38/DD0+5hEybkTiapmlgkJGkZTJkC228Pl1ySds55+OF08rBUTrbZJv3d/Pvf4dVXYeut4Ygj4O23MweTVBUsEpLURKNHp/37X3op7cj0+9+nKSVSOWrTBn70ozTdacgQKBbTdKcLL4S5c3Onk1TJLBKS1EiffAJHHQWDB6eFrE88AQcemDuV1DhduqST1SdNShsDnHoq9O0LN98MMeZOJ6kSWSQkqRGefRa22gr+8pf0Buz//g969sydSmq6DTaAm26CO+6A9u1hwADYc0947rncySRVGouEJC1FjHDFFVBTk06rvvPOtBNO+/a5k0nLZ4890mF2v/kNPPII9OsHJ54IH3yQO5mkSmGRkKQlmDkTvvc9OPJI2G679KZr991zp5KaT/v2cMIJab3PkUemk7I33BD+/Od0wKIkLY1FQpIWo7YWttwSxo6FESPSSMSaa+ZOJZVG9+7wpz/B44+n9T9HHw39+6cpfJK0JBYJSaonxjTVY7vt0jkR99+fTgdu2zZ3Mqn0Nt88/Z0fPRpmzICddkoH2913X1onNG2aIxWSPhdilWzVUFNTE2tra3PHkFTBpk9Pe+zfcktagPq3v8HXvpY7lZTHJ5/AxRenbWI//fTz+9u0Sf8uVl89jWR07/7Fr798u2tXi7hUaUIIj8UYaxq8ziIhSfDgg3DYYek3rhdfDP/7vxBC7lRSfu++m7aMfe+99O/js4/6t997L41gLE4IqUw0pnSsvrrFQyoHjS0S7VoijCSVq4ULYeRIOOcc+MY34KGH0toISckaa6SPhixYkEb1Flcy6heQZ55Jn2fMWPz5FSGkEY/GlI7PRjza+W5GysJ/epJarbffhh/8AO69F77/ffjjH9OhXZKarl27xpcOSMVjxoyll4733vt8bcb06UsuHqut1vipVt26WTxUejGmKYEffwyzZqXPjfmYNSutS/re93L/BI3jPyVJrdIdd8Dhh8Ps2XDllWlthFOZpJbTrl16g7/66o27fuHCz0c8ljbq8fzzabepJRUP+HzEozGjHhaP1mPu3Ma90W9sIWjsxgQrrJB+ifXZx8cfl/bnbE7+05DUqsyfD2ecARddlA7gGj0aNt44dypJDWnbtunF48sjHosb9Xj++bRGavp0WLRo8c+12mqNn2rVrZsHVraU+fOX7U3+kq6fP79xr9uhwxff+Hfpkv6OrLfeV+/v0gVWWmnx93/2vUouqhUcXZKa5pVX0oLqRx5J++Rfckn6TZCk6tO27edv8hvjs+KxtAXl06bBiy/C+PHw/vtLLh6rrtq0qVYdOjTfz13OFi5s+jSfpX1/7tzGvW67dot/E7/WWkt+g7+0N/6t5c+rMSwSklqFa69NJ/fGCGPGwKBBuRNJKifLUjw++GDJazs++3ryZPj3vxsuHk2ZatVSb2QXLUrTP5dnik/9j/rbCC9NmzaL/y1+t25Lf4O/pO917OjU1VIpaZEIIewJXAq0Bf4aY7xgCdcdDIwFvhVjrA0h7AZcAHQA5gE/jzHeW8qskqrTp5/CSSelU3u32gpGjYJevXKnklTp2rZNb2y7dWvc9MhFi1LxaGgb3cmT0+5x77+/5Dn2q6zScOn4rBAtz2/+Z89e8jqTL1vcG/l11234Tf7iPlZYwTf+laJkRSKE0Ba4DNgNmAo8GkIYF2N89kvXdQGOBx6pd/f7wH4xxrdCCH2BO4F1SpVVUnV6/vm0+8VTT8Epp8CIEQ5JS8qjTZu0VW3Xrk0rHkvb0WraNJgyBR5+eOnFY3G+vMC3S5e049YGGzT9t/6dO6efT61PKUcktgImxxinAIQQRgEDgWe/dN1w4CLglM/uiDE+Ue/7k4BOIYSOMcZGzoaT1JrFCFddBcceCyuuCLfdBnvtlTuVJDVe/eLxzW82fP2iRfDhh18sGW3aLLkQeOifmkMpi8Q6wBv1bk8Ftq5/QQhhC2DdGOMtIYRTWLyDgCcWVyJCCEcBRwGst956zRJaUmX7+GM45hi45hrYeef0ee21c6eSpNJq0yZta/u1r8FGG+VOo9ailANRi5vd9p+ZdiGENsCvgZOX+AQhbAJcCPx0cd+PMV4eY6yJMdZ0b+zqKElV64knoH9/KBRg2DC4+25LhCRJpVLKIjEVWLfe7R7AW/VudwH6AveHEF4FtgHGhRBqAEIIPYAbgMNjjC+XMKekChcj/O53sM028MkncN99cOaZDt1LklRKpSwSjwK9Qwi9QggdgMHAuM++GWP8KMbYLcbYM8bYE3gYGFC3a9OqwK3AaTHG8SXMKKnCzZgBBx4Ixx8Pu+8OEyfCjjvmTiVJUvUrWZGIMS4AjiPtuPQcMCbGOCmEMCyEMKCBhx8HbACcGUKYWPfRyLMsJbUW48fDFlvArbemw+XGjUtbMUqSpNILsbEbBJe5mpqaWFtbmzuGpBawaBFccAGcdRZ8/eswejTU1OROJUlSdQghPBZjbPC/rO76K6niDBkCp58OBx8Mjz9uiZAkKYeSnmwtSc1t3jy44opUIopFTz+VJCkXRyQkVZS77kqnvR5xhCVCkqScLBKSKkqhkA5c2m233EkkSWrdLBKSKsbs2XDTTTBoEHTokDuNJEmtm0VCUsUYNy4dOHfYYbmTSJIki4SkilEswjrrwA475E4iSZIsEpIqwowZcMcdMHgwtPH/uSRJys7/HEuqCNddB/Pnw/e+lzuJJEkCi4SkClEowIYbwhZb5E4iSZLAIiGpArz5JjzwQBqN8OwISZLKg0VCUtkbPRpidLcmSZLKiUVCUtkrFqF//zS1SZIklQeLhKSy9tJLUFvraIQkSeXGIiGprBWLaV3EoYfmTiJJkuqzSEgqWzGm3Zp23BF69MidRpIk1WeRkFS2Jk6EF17w7AhJksqRRUJS2SoUoH17OOig3EkkSdKXWSQklaVFi2DUKNhjD+jaNXcaSZL0ZRYJSWXpX/+CqVOd1iRJUrmySEgqS4UCrLgiDBiQO4kkSVoci4SksjNvHowdCwMHQufOudNIkqTFsUhIKjt33w0zZngInSRJ5cwiIansFIuw2mppobUkSSpPFglJZeWTT+DGG+Hgg6FDh9xpJEnSklgkJJWVm2+G2bPdrUmSpHJnkZBUVgoFWHtt2GGH3EkkSdLSWCQklY0PPoDbb4fBg6Ft29xpJEnS0lgkJJWN666D+fPdrUmSpEpgkZBUNopF6N0b+vfPnUSSJDXEIiGpLLz1Ftx3XxqNCCF3GkmS1BCLhKSyMGYMxOi0JkmSKoVFQlJZKBRgiy3gm9/MnUSSJDWGRUJSdpMnw6OPenaEJEmVxCIhKbtiMX0+9NC8OSRJUuNZJCRlFWOa1rTjjrDuurnTSJKkxrJISMrqySfh+eddZC1JUqWxSEjKqliEdu3g4INzJ5EkSU1hkZCUzaJFqUjssQd065Y7jSRJagqLhKRsxo+HN95wWpMkSZXIIiEpm2IRVlgBBg7MnUSSJDWVRUJSFvPnp9OsBwyAlVbKnUaSJDWVRUJSFv/8J0yf7iF0kiRVKouEpCwKBVh11bTQWpIkVR6LhKQW98kncOONacvXjh1zp5EkScvCIiGpxd1yC8ya5W5NkiRVMouEpBZXLMJaa8FOO+VOIkmSlpVFQlKL+vBDuO02OPRQaNs2dxpJkrSsLBKSWtT118O8ee7WJElSpbNISGpRhQKsvz7U1OROIkmSlodFQlKLefttuO++NBoRQu40kiRpeVgkJLWYMWNg0SJ3a5IkqRqUtEiEEPYMIbwQQpgcQjh1KdcdHEKIIYSaevedVve4F0IIHlklVYFiETbfHDbeOHcSSZK0vEpWJEIIbYHLgL2APsBhIYQ+i7muC3A88Ei9+/oAg4FNgD2BP9Q9n6QK9fLL8MgjjkZIklQtSjkisRUwOcY4JcY4DxgFDFzMdcOBi4A59e4bCIyKMc6NMb4CTK57PkkVatSo9Hnw4Lw5JElS8yhlkVgHeKPe7al19/1HCGELYN0Y4y1NfWzd448KIdSGEGqnTZvWPKklNbsY025N228P662XO40kSWoOpSwSi9uTJf7nmyG0AX4NnNzUx/7njhgvjzHWxBhrunfvvsxBJZXW00/Ds896doQkSdWkXQmfeyqwbr3bPYC36t3uAvQF7g9pH8g1gXEhhAGNeKykClIoQLt2MGhQ7iSSJKm5lHJE4lGgdwihVwihA2nx9LjPvhlj/CjG2C3G2DPG2BN4GBgQY6ytu25wCKFjCKEX0BuYUMKskkpk0aK0PmK33aBbt9xpJElScylZkYgxLgCOA+4EngPGxBgnhRCG1Y06LO2xk4AxwLPAHcCxMcaFpcoqqXQeeghee81pTZIkVZsQ41eWHlSkmpqaWFtbmzuGpC859li48kp47z3o0iV3GkmS1JAQwmMxxpqGrvNka0klM38+jB0LAwZYIiRJqjYWCUklc889MG2ah9BJklSNLBKSSqZYhFVWgb32yp1EkiQ1N4uEpJL49FO4/no46CDo2DF3GkmS1NwsEpJK4tZbYdYsd2uSJKlaWSQklUShAGuuCd/5Tu4kkiSpFCwSkprdhx/CbbfBoYdC27a500iSpFKwSEhqdjfcAHPnuluTJEnVzCIhqdkVi/CNb8BWW+VOIkmSSsUiIalZvfNOOj/isMMghNxpJElSqVgkJDWrsWNh0SJ3a5IkqdpZJCQ1q0IBNt0U+vTJnUSSJJWSRUJSs5kyBR5+2NEISZJaA4uEpGYzalT6PHhw3hySJKn0LBKSmk2xCN/+Nnz967mTSJKkUrNISGoWTz8Nzzzj2RGSJLUWFglJzaJYTKdYDxqUO4kkSWoJFglJyy3GVCR22w1WXz13GkmS1BIsEpKW28MPw6uvOq1JkqTWxCIhabkVCtCpE+y/f+4kkiSppVgkJC2XBQtgzBjYd19YeeXcaSRJUkuxSEhaLvfeC++95yF0kiS1NhYJSculUEgjEXvtlTuJJElqSRYJScvs00/h+uvhoIPSGglJktR6WCQkLbPbboOPP3a3JkmSWiOLhKRlVizCGmvAzjvnTiJJklqaRULSMvnoI7jlFjjkEGjXLncaSZLU0iwSkpbJjTfC3Lnu1iRJUmtlkZC0TAoF6NULtt46dxJJkpSDRUJSk737LtxzT1pkHULuNJIkKQeLhKQmGzsWFi50tyZJklozi4SkJisWoV8/6Ns3dxJJkpSLRUJSk7z6Kvz7345GSJLU2lkkJDXJqFHp8+DBeXNIkqS8LBKSmqRQgG23TTs2SZKk1ssiIanRnnkGnn7asyMkSZJFQlITFIvQpg0MGpQ7iSRJys0iIalRYkxFYtddYY01cqeRJEm5WSQkNcojj8ArrzitSZIkJRYJSY1SKEDHjnDAAbmTSJKkcmCRkNSgBQtgzBjYd19YeeXcaSRJUjmwSEhq0H33wbvvegidJEn6nEVCUoOKxTQSsffeuZNIkqRyYZGQtFRz5sB116W1ESuskDuNJEkqFxaJZvTqq7kTSM3v9tth5kx3a5IkSV9kkWgmI0ZA375pHrlUTQoFWH112GWX3EkkSVI5sUg0k0MOSVNARo7MnURqPjNnwi23pL/f7drlTiNJksqJRaKZ9O4NP/kJ/OlP8NprudNIzePGG1NBdrcmSZL0ZRaJZnTWWRACnHNO7iRS8ygWoWdP2Hbb3EkkSVK5sUg0ox494Ljj4B//gGefzZ1GWj7TpsHdd8PgwakgS5Ik1deoIhFCOCGEsHJIrgghPB5C2L3U4SrRqadC585wxhm5k0jLZ+xYWLjQ3ZokSdLiNXZE4icxxpnA7kB34MfABSVLVcG6dYNTToEbboAJE3KnkZZdoQCbbAL9+uVOIkmSylFji8RnExv2Bv4WY3yy3n36kp/9DLp3h6FDcyeRls1rr8H48Y5GSJKkJWtskXgshHAXqUjcGULoAixq6EEhhD1DCC+EECaHEE5dzPePDiE8HUKYGEL4VwihT9397UMIV9V977kQwmlN+aFy69IllYh77kkfUqUZNSp9Hjw4bw5JklS+Qoyx4Ytqhq3lAAAgAElEQVRCaANsDkyJMX4YQvga0CPG+NRSHtMWeBHYDZgKPAocFmN8tt41K9dNmSKEMAA4Jsa4Zwjhe8CAGOPgEMKKwLPAd2KMry7p9WpqamJtbW3DP3ELmTMHNtwQ1loLHn7YxaqqLJtvDiusAA89lDuJJElqaSGEx2KMNQ1d19gRiW2BF+pKxA+AM4CPGnjMVsDkGOOUGOM8YBQwsP4Fn5WIOp2Bz1pNBDqHENoBKwDzgPrXlr1OndI2sBMmpL34pUrx7LPw5JOeHSFJkpausUXij8AnIYTNgF8ArwH/aOAx6wBv1Ls9te6+LwghHBtCeBm4CDi+7u5rgdnA28DrwC9jjDMW89ijQgi1IYTaadOmNfJHaTmHHw7f/GbawWnhwtxppMYpFqFNm3SatSRJ0pI0tkgsiGkO1EDg0hjjpUCXBh6zuMk8X5lHFWO8LMa4PjCENNIBaTRjIbA20As4OYTwjcU89vIYY02MsaZ79+6N/FFaTrt2MHx4+g3vNdfkTiM1LMa0W9N3vwtrrpk7jSRJKmeNLRIf1y14/iFwa936h/YNPGYqsG692z2At5Zy/Shg/7qvvwfcEWOcH2N8DxgPNDhPqxwddBD07w9nnw1z5+ZOIy3do4/ClClOa5IkSQ1rbJE4FJhLOk/iHdIUpYsbeMyjQO8QQq8QQgdgMDCu/gUhhN71bu4DvFT39evALnUH4HUGtgGeb2TWshICnH9+2k7z8stzp5GWrlCAjh3hwANzJ5EkSeWuUUWirjz8P2CVEMK+wJwY41LXSMQYFwDHAXcCzwFjYoyTQgjD6nZoAjguhDAphDAROAn4Ud39lwErAc+QCsnflrZDVLnbdVfYeWc47zyYNSt3GmnxFi6E0aNh771hlVVyp5EkSeWuXWMuCiEcQhqBuJ+09uF3IYSfxxivXdrjYoy3Abd96b6z6n19whIeNwsY1JhslSAEGDkStt0WLr0UTj89dyLpq+6/H955x0PoJElS4zR2atPpwLdijD+KMR5OWgx9ZuliVZ9ttoGBA+Hii2HGV/afkvIrFNJhivvskzuJJEmqBI0tEm3qFj1/ZnoTHqs6550HM2fChRfmTiJ90dy5cN11cMAB6SA6SZKkhjS2DNwRQrgzhHBECOEI4Fa+NGVJDevbF37wA/jtb+Gtpe1fJbWw22+Hjz5ytyZJktR4jV1s/XPgcmBTYDPg8hjjkFIGq1bnnpsWtQ4fnjuJ9LliEbp3T+dHSJIkNUajpyfFGK+LMZ4UY/xZjPGGUoaqZr16wVFHwV//Ci+/nDuNBB9/DOPGwaBB0L6h02EkSZLqLLVIhBA+DiHMXMzHxyGEmS0VstqccQZ06ABnndXwtVKp3XQTzJnjbk2SJKlpllokYoxdYowrL+ajS4xx5ZYKWW3WXBNOOCHtkvPkk7nTqLUrFGC99dL2xJIkSY3lzkuZ/PznsOqqnimhvKZNg7vuSous2/j/BpIkqQl865DJaqvBkCFw660wfnzuNGqtrr02Lf53tyZJktRUFomMjj8+TXM67TSIMXcatUbFIvTpA5tumjuJJEmqNBaJjFZcEc48Ex58EO64I3catTavv57+7h12GISQO40kSao0FonMjjwybQk7dCgsWpQ7jVqT0aPTZ6c1SZKkZWGRyKxDBxg2DCZOhLFjc6dRa1IowFZbwfrr504iSZIqkUWiDBx2GPTtm6Y5zZ+fO41ag+eeS+XVsyMkSdKyskiUgbZtYcQIeOkl+Pvfc6dRa1Aspu1eDzkkdxJJklSpLBJlYr/90oFg554Ln36aO42qWYypSOy8M6y1Vu40kiSpUlkkykQIcP758Oab8Ic/5E6jalZbC5MnO61JkiQtH4tEGdlpJ9hjj1QoZs7MnUbVqlhMi/wPPDB3EkmSVMksEmVm5EiYPh1+9avcSVSNFi6EUaNg771h1VVzp5EkSZXMIlFmttwSBg2CSy6BadNyp1G1eeABePttz46QJEnLzyJRhoYPTwuuR47MnUTVpliElVaCfffNnUSSJFU6i0QZ2mgjOOKItOj69ddzp1G1mDsXrr0W9t8fVlwxdxpJklTpLBJl6uyz005O556bO4mqxZ13wocfuluTJElqHhaJMrXuunDMMemAuuefz51G1aBQgK5dYdddcyeRJEnVwCJRxk47LU1BOeOM3ElU6WbNgnHj0knW7dvnTiNJkqqBRaKMde8OJ58M112XDhGTltVNN6UF/O7WJEmSmotFosyddFKajjJ0aO4kqmTFYpou9+1v504iSZKqhUWizK28cioRd98N992XO40q0fTpaaH14MHQxn/xkiSpmfi2ogIccwz06JHWTMSYO40qzbXXwoIF7tYkSZKal0WiAnTqlLaDfeSRtGBWaopCAb75Tdhss9xJJElSNbFIVIgjjoANN4TTT4eFC3OnUaV44w148ME0GhFC7jSSJKmaWCQqRLt2MHw4TJqUfsMsNcbo0Wk6nLs1SZKk5hZilUy6r6mpibVVvkfqokVQU5NOJ37+eejQIXcilbv+/aFtW5gwIXcSSZJUKUIIj8UYaxq6zhGJCtKmDYwcCa+8An/5S+40KncvvACPP+5ohCRJKg2LRIXZYw/Yaac0zWn27NxpVM6KxbQu4tBDcyeRJEnVyCJRYUKA88+Hd9+F3/42dxqVqxjTWprvfAfWXjt3GkmSVI0sEhVo221hv/3goovggw9yp1E5evxxeOklz46QJEmlY5GoUCNGwEcfpTIhfVmhAO3bw0EH5U4iSZKqlUWiQvXrl37bfOml8PbbudOonCxcCKNGwV57wWqr5U4jSZKqlUWigp17LsyfD+edlzuJysmDD8JbbzmtSZIklZZFooKtvz7893/D5ZfDlCm506hcFArQuXNaRyNJklQqFokKd+aZaS782WfnTqJyMG8eXHst7L8/rLhi7jSSJKmaWSQq3FprwfHHw//7f/D007nTKLc770w7eXkInSRJKjWLRBUYMgRWXhlOPz13EuVWLELXrrD77rmTSJKkameRqAKrrQa/+AXcfDP8+9+50yiX2bPhppvg4IPTdDdJkqRSskhUiRNOgDXWgKFD06nGan3GjYNPPnG3JkmS1DIsElWic2c44wx44AG4667caZRDoQA9esD22+dOIkmSWgOLRBU56ijo2TONSixalDuNWtL06XDHHTB4MLTxX7UkSWoBvuWoIh06pEPqHn8crrsudxq1pOuugwUL3K1JkiS1HItElfn+92GTTdL5EgsW5E6jllIswkYbwRZb5E4iSZJaC4tElWnbFs47D154Aa66KncatYQ330xrYw47DELInUaSJLUWFokqNHAgbL01nHMOzJmTO41KbfTotFOX05okSVJLKmmRCCHsGUJ4IYQwOYRw6mK+f3QI4ekQwsQQwr9CCH3qfW/TEMJDIYRJddd0KmXWahICjBwJU6fCH/+YO41KrVCA/v1hww1zJ5EkSa1JyYpECKEtcBmwF9AHOKx+UahTiDH2izFuDlwEXFL32HbANcDRMcZNgO8A80uVtRrtsgvstlsqFB9/nDuNSuXFF+Gxxzw7QpIktbxSjkhsBUyOMU6JMc4DRgED618QY5xZ72Zn4LOj1HYHnooxPll33fQY48ISZq1KI0fC++/DJZfkTqJSKRbTCNShh+ZOIkmSWptSFol1gDfq3Z5ad98XhBCODSG8TBqROL7u7g2BGEK4M4TweAjhF4t7gRDCUSGE2hBC7bRp05o5fuWrqYGDDoJf/SoVClWXGFOR2GknWOcr/7IkSZJKq5RFYnH7x8Sv3BHjZTHG9YEhwBl1d7cDtge+X/f5gBDCdxfz2MtjjDUxxpru3bs3X/IqMnw4zJ4N55+fO4ma2xNPpN25nNYkSZJyKGWRmAqsW+92D+CtpVw/Cti/3mMfiDG+H2P8BLgN2LIkKavcxhvDj34El10Gb7zR8PWqHMUitG+fRp0kSZJaWimLxKNA7xBCrxBCB2AwMK7+BSGE3vVu7gO8VPf1ncCmIYQV6xZe7wQ8W8KsVe2cc9I0mGHDcidRc1m0CEaNgj33hK99LXcaSZLUGpWsSMQYFwDHkUrBc8CYGOOkEMKwEMKAusuOq9vedSJwEvCjusd+QNrB6VFgIvB4jPHWUmWtduutB//zP3DllWkqjCrfv/6Vtvf17AhJkpRLiPEryxYqUk1NTaytrc0do2y99x584xuw994wZkzuNFpeRx8NV1+d/lw7d86dRpIkVZMQwmMxxpqGrvNk61Zi9dXhpJNg7Fh4/PHcabQ85s1Lf44DB1oiJElSPhaJVuTkk9N8+qFDcyfR8rj7bpgxw92aJElSXhaJVmSVVeC00+DOO+GBB3Kn0bIqFGC11WD33XMnkSRJrZlFopU59th0eNlpp6WdnFRZZs+Gm26CQYOgQ4fcaSRJUmtmkWhlVlgBzjoLHnoIbrkldxo11c03pzLhbk2SJCk3i0Qr9OMfwwYbwOmnp/MIVDmKxTSitMMOuZNIkqTWziLRCrVvD8OHw9NPpzemqgwzZsDtt8Ohh0LbtrnTSJKk1s4i0Uodcghsvnma5jRvXu40aozrr4f5892tSZIklQeLRCvVpg2MGAFTpsAVV+ROo8YoFKB3b9hyy9xJJEmSLBKt2l57wfbbp2lOn3ySO42W5q234P7702hECLnTSJIkWSRatRDg/PPh7bfhd7/LnUZLM3p02q7X3ZokSVK5sEi0cttvD/vsAxdeCB9+mDuNlqRYTFOaNtoodxJJkqTEIiFGjIAPPoCLL86dRIvz0kvw6KOORkiSpPJikRCbbZbepP7mN/DOO7nT6MtGjUrT0AYPzp1EkiTpcxYJATBsWNoGdsSI3ElUX4xpt6YddoAePXKnkSRJ+pxFQkA66fq//gv+/Gd45ZXcafSZJ5+E55/37AhJklR+LBL6jzPPTCcmn3127iT6TKEA7drBwQfnTiJJkvRFFgn9xzrrwP/+L1xzDTzzTO40WrQorY/YYw/o2jV3GkmSpC+ySOgLhgyBLl3gjDNyJ9H48fDGG05rkiRJ5ckioS/o2hV+/nO46SZ4+OHcaVq3QgFWWAEGDMidRJIk6assEvqKE0+E1VeHoUPTrkFqefPnw9ixMHAgrLRS7jSSJElfZZHQV6y0Epx+Otx3H/zzn7nTtE533w3Tp3sInSRJKl8WCS3WT38KX/+6oxK5FIuw2mqw5565k0iSJC2eRUKL1bEjnHMO1NbC9dfnTtO6fPIJ3HADHHQQdOiQO40kSdLiWSS0RD/8IWy8cdrBacGC3Glaj1tugdmz3a1JkiSVN4uElqhtWzjvvHSy8tVX507TehQKsNZasOOOuZNIkiQtmUVCS3XAAfCtb6VpTnPn5k5T/T74AG6/HQYPTkVOkiSpXFkktFQhwMiR8Prr8Kc/5U5T/a6/HubNc7cmSZJU/iwSatCuu8Iuu8CIEfDxx7nTVLdiETbYAGpqcieRJElaOouEGmXkSJg2DX7zm9xJqtfbb8O996bRiBByp5EkSVo6i4QaZeut03qJX/4yHZSm5jdmTDqzw2lNkiSpElgk1GjnnQezZsEFF+ROUp0KBdh887TlriRJUrmzSKjR+vRJZ0v8/vfw5pu501SXl1+GCRM8O0KSJFUOi4Sa5JxzYOFCGDYsd5LqUiymz4cemjeHJElSY1kk1CQ9e8LRR8MVV8CLL+ZOUx1iTNOadtgB1lsvdxpJkqTGsUioyU4/HTp1grPOyp2kOjz1FDz3nIusJUlSZbFIqMnWWANOPBFGj4YnnsidpvIVi9CuHQwalDuJJElS41kktExOOQVWWy2NTmjZLVqUisTuu0O3brnTSJIkNZ5FQstk1VXh1FPh9tvhwQdzp6lcDz0Er7/utCZJklR5LBJaZscdB2utBaedlhYMq+kKBVhhBRg4MHcSSZKkprFIaJmtuGJacD1+PNx2W+40lWf+/HSa9X77QZcuudNIkiQ1jUVCy+W//gvWXz+tlVi0KHeaynLPPfD++x5CJ0mSKpNFQsulfft0ON2TT6ZdnNR4hUJaa7LnnrmTSJIkNZ1FQstt8GDYdFM488w0XUcN+/RTuOEGOOgg6NgxdxpJkqSms0houbVpAyNGwMsvw5VX5k5TGW65BWbNcrcmSZJUuSwSahb77APbbZemOX36ae405a9YhDXXhO98J3cSSZKkZWORULMIAc4/H956C37/+9xpytuHH8Ktt8Khh0LbtrnTSJIkLRuLhJrNjjumhcMXXAAffZQ7Tfm64QaYN8/dmiRJUmWzSKhZjRwJM2bAL3+ZO0n5KhTSlrnf+lbuJJIkScvOIqFmtcUWacrOr38N776bO035eecduPfetMg6hNxpJEmSlp1FQs1u+HCYMyeNTuiLxoxJB/e5W5MkSap0Fgk1u9694Sc/gT/9CV59NXea8lIswmabQZ8+uZNIkiQtn5IWiRDCniGEF0IIk0MIpy7m+0eHEJ4OIUwMIfwrhNDnS99fL4QwK4RwSilzqvmddVaaunPOObmTlI8pU+Dhhx2NkCRJ1aFkRSKE0Ba4DNgL6AMc9uWiABRijP1ijJsDFwGXfOn7vwZuL1VGlU6PHnDccXD11fDss7nTlIdRo9LnwYPz5pAkSWoOpRyR2AqYHGOcEmOcB4wCBta/IMY4s97NzkD87EYIYX9gCjCphBlVQqeeCp07wxln5E5SHgoF+Pa34etfz51EkiRp+ZWySKwDvFHv9tS6+74ghHBsCOFl0ojE8XX3dQaGAOeWMJ9KrFs3OOWUdG7ChAm50+T19NMwaZJnR0iSpOpRyiKxuM0t41fuiPGyGOP6pOLw2e+uzwV+HWOctdQXCOGoEEJtCKF22rRpyx1Yze9nP4Pu3WHo0NxJ8ioU0inWgwblTiJJktQ8SlkkpgLr1rvdA3hrKdePAvav+3pr4KIQwqvAicDQEMJxX35AjPHyGGNNjLGme/fuzZNazapLl1Qi7rknfbRGMabdmnbbLZUqSZKkalDKIvEo0DuE0CuE0AEYDIyrf0EIoXe9m/sALwHEGHeIMfaMMfYEfgOMjDH+voRZVUJHHw3rrpsKRfzKmFT1e+gheO01pzVJkqTqUrIiEWNcABwH3Ak8B4yJMU4KIQwLIQyou+y4EMKkEMJE4CTgR6XKo3w6dUrbwE6YADfemDtNyysW0/8G++/f8LWSJEmVIsQq+RVxTU1NrK2tzR1DS7BgAfTrB23awFNPpfUCrcGCBbD22vCd76RTrSVJkspdCOGxGGNNQ9d5srVaRLt2MHx4OlPimmtyp2k599wD06Z5CJ0kSao+Fgm1mIMOgv794eyzYe7c3GlaRrEIq6wCe+2VO4kkSVLzskioxYQAI0emhceXX547Tel9+ilcfz0ceGBaIyFJklRNLBJqUbvtltYLnHcezFrqKSGV77bb4OOP3a1JkiRVJ4uEWlQIcP758N57cOmludOUVqEAa6wBO++cO4kkSVLzs0ioxW2zDQwYABdfDDNm5E5TGh99BLfeCoce2np2qJIkSa2LRUJZjBgBM2fChRfmTlIaN9yQFpS7W5MkSapWFgll0bcv/OAH8Nvfwltv5U7T/IpF6NULtt46dxJJkqTSsEgom3PPhYUL0/kS1eTdd+Gf/0yjESHkTiNJklQaFgll06sXHHUU/PWvMHly7jTNZ+xYWLTI3ZokSVJ1s0goqzPOgA4d4KyzcidpPoUC9OsHm2ySO4kkSVLpWCSU1ZprwgknpDUFTz6ZO83ye+UVeOghRyMkSVL1s0gou5//HFZdFU4/PXeS5TdqVPo8eHDeHJIkSaVmkVB2q60GQ4akcxfGj8+dZvkUi7DddtCzZ+4kkiRJpWWRUFk4/vg0zem00yDG3GmWzTPPwNNPe3aEJElqHSwSKgsrrghnngkPPgh33JE7zbIpFtMp1oMG5U4iSZJUehYJlY0jj0xbwg4dmrZPrSQxpiKx666wxhq500iSJJWeRUJlo0MHGDYMJk5MZzFUkkceSTs2Oa1JkiS1FhYJlZXDDoO+fdM0p/nzc6dpvEIBOnaEAw7InUSSJKllWCRUVtq2hREj4KWX4O9/z52mcRYsgDFjYN99YeWVc6eRJElqGRYJlZ399oNtt4Vzz4VPP82dpmH33QfvvushdJIkqXWxSKjshAAjR8Kbb8If/pA7TcMKhTQSsffeuZNIkiS1HIuEytJ3vgO77w7nnw8zZ+ZOs2Rz5sD118OBB0KnTrnTSJIktRyLhMrWyJEwfTr86le5kyzZbbelouNuTZIkqbWxSKhs9e8PBx8Ml1wC06blTrN4xSKsvjrsskvuJJIkSS3LIqGyNnw4fPJJGp0oNzNnws03wyGHQLt2udNIkiS1LIuEyto3vwk//nFadP3aa7nTfNGNN8Lcue7WJEmSWieLhMre2WennZzOPTd3ki8qFKBnT9hmm9xJJEmSWp5FQmVv3XXhmGPgqqvguedyp0neew/++c+0yDqE3GkkSZJankVCFeG002DFFeHMM3MnScaOhYUL3a1JkiS1XhYJVYTu3eHkk+G666C2NneatFtT377Qr1/uJJIkSXlYJFQxTjoJunaFoUPz5njtNRg/3tEISZLUulkkVDFWXjmViLvvhvvuy5dj1Kj02SIhSZJaM4uEKsoxx0CPHmnNRIx5MhQKaaemXr3yvL4kSVI5sEioonTqlLaDfeQRGDeu5V9/0iR46inPjpAkSbJIqOIccQRsuCGcfnraOaklFYvQpk06zVqSJKk1s0io4rRrB8OHp9GBQqHlXjfGVCS++11YY42We11JkqRyZJFQRTr4YNhiizTNad68lnnNCRNgyhSnNUmSJIFFQhWqTRsYORJeeQX+8peWec1iETp2hAMOaJnXkyRJKmcWCVWsPfaAHXdM05xmzy7tay1cCKNHwz77wCqrlPa1JEmSKoFFQhUrBDj/fHj3Xfjtb0v7WvffD++849kRkiRJn7FIqKJttx3suy9cdBF88EHpXqdQgC5d0oiEJEmSLBKqAiNGwEcfpTJRCnPnwnXXpbURK6xQmteQJEmqNBYJVbxNN01Tji69FN5+u/mf//bbU1FxtyZJkqTPWSRUFYYNg/nz08Lr5lYoQPfu6fwISZIkJRYJVYX114f//u+0FezLLzff8378Mdx8czrJul275nteSZKkSmeRUNU480xo3z4dUtdcbrwR5sxxtyZJkqQvs0ioaqy1Fhx/fJqK9PTTzfOcxSJ8/euw7bbN83ySJEnVwiKhqjJkCKy8Mpx++vI/17RpcNddMHhwOklbkiRJn/PtkarKaqvBL36R1jX8+9/L91zXXptOtHa3JkmSpK+ySKjqnHACrLEGDB0KMS778xQK0KcP9OvXfNkkSZKqhUVCVadzZzjjDHjggTQ1aVm8/jr8619pNCKE5s0nSZJUDSwSqkpHHQU9e6ZRiUWLmv74UaPS58GDmzWWJElS1ShpkQgh7BlCeCGEMDmEcOpivn90COHpEMLEEMK/Qgh96u7fLYTwWN33Hgsh7FLKnKo+HTrAuefC44/Dddc1/fHFImy9dTqfQpIkSV9VsiIRQmgLXAbsBfQBDvusKNRTiDH2izFuDlwEXFJ3//vAfjHGfsCPgKtLlVPV6/vfh002SedLLFjQ+Mc99xxMnOjZEZIkSUtTyhGJrYDJMcYpMcZ5wChgYP0LYowz693sDMS6+5+IMb5Vd/8koFMIoWMJs6oKtW0L550HL7wAV13V+McVi2m710MOKV02SZKkSlfKIrEO8Ea921Pr7vuCEMKxIYSXSSMSxy/meQ4Cnogxzl3MY48KIdSGEGqnTZvWTLFVTQYOTFOUzjknnVDdkBjTbk277JIOuNP/b+9uYywd7ziOf392qfW4FauRXcEioqSWDkm7rQjaKKIIqbZovNBGaKgXVUI8pJE2KekblHgI8Wx1Y9OytNpuq4myu13dstoiGhOaJa2HVQ+1/n1xbslizTm3zLjn7Hw/yWTnvveaM7+TK5OZ37mv+zqSJEnrN5FFYn173XxgM86quryqdgHOBs57zwMkewI/Br6zvm9QVVdX1UhVjcyaNWscImtDk8All8DoKFx5Zf/xS5fCU0+5rEmSJKmfiSwSo8AO6xzPAZ77kLHQW/p01LsHSeYAC4GTquqpCUmoKeGgg+CQQ3qF4tVXxx57yy29G7WPOebjySZJkjSsJrJIPALslmTnJJsAxwOL1h2QZLd1Dg8H/tGcnwn8Ejinqv44gRk1RVxyCbz4Ilx22YePWbsWbr8dDjsMZs78+LJJkiQNowkrElX1NnA6cB+wCrijqh5LcnGSI5thpyd5LMkK4Cx6OzTRfN2uwPnN1rArkmw3UVm14dtvv95Vhksv7RWK9VmyBJ5/vvcmdJIkSRpbqj5w28JQGhkZqaVLl3YdQ5PYqlWw115w5pm9QvF+p5zSeyO61athxoyPP58kSdJkkGRZVY30G+c7W2vK2GMPOOkkuPxyePbZ9/7fm2/CggVw9NGWCEmSpEFYJDSlXHhhb4vXiy567/nFi+Gll9ytSZIkaVAWCU0pO+4Ip54K11/fe6O6d916K2y7bW93J0mSJPVnkdCUc+65veVL55/fO16zBhYtguOOg4037jabJEnSsLBIaMrZbjs46yy4805Yvhzuvhtef93dmiRJktpw1yZNSS+/DHPn9raFnTYNVq6EZ56BjazWkiRpinPXJmkMW28N55wD990H997bu8naEiFJkjQ4/3TSlHXaaTB7dm8XJ3drkiRJamd61wGkrsyYAVdc0bsisffeXaeRJEkaLhYJTWlHHtn7kCRJUjsubZIkSZLUmkVCkiRJUmsWCUmSJEmtWSQkSZIktWaRkCRJktSaRUKSJElSaxYJSZIkSa1ZJCRJkiS1ZpGQJEmS1JpFQpIkSVJrFglJkiRJrVkkJEmSJLVmkZAkSZLUmkVCkiRJUmsWCUmSJEmtWSQkSbYuus0AAAW8SURBVJIktWaRkCRJktSaRUKSJElSa6mqrjOMiyQvAP/sOMa2wIsdZ1B7zttwct6Gk/M2nJy34eS8DafJMG87VtWsfoM2mCIxGSRZWlUjXedQO87bcHLehpPzNpyct+HkvA2nYZo3lzZJkiRJas0iIUmSJKk1i8T4urrrAPpInLfh5LwNJ+dtODlvw8l5G05DM2/eIyFJkiSpNa9ISJIkSWrNIiFJkiSpNYvEOElyaJK/JXkyyQ+6zqP+klyXZHWSv3adRYNLskOS3yZZleSxJGd0nUn9Jdk0ycNJHm3m7aKuM2kwSaYl+XOSX3SdRYNJ8kySlUlWJFnadR4NJsnMJAuSPNH8jvtc15n68R6JcZBkGvB34EvAKPAI8PWqerzTYBpTkgOANcCNVbVX13k0mCTbA9tX1fIkWwLLgKP8eZvckgTYvKrWJNkYeBA4o6oe6jia+khyFjACbFVVR3SdR/0leQYYqaqu39RMLSS5AfhDVV2TZBNgs6p6qetcY/GKxPjYH3iyqp6uqreA24CvdpxJfVTV74F/d51D7VTV81W1vPn8VWAVMLvbVOqnetY0hxs3H76SNcklmQMcDlzTdRZpQ5ZkK+AA4FqAqnprspcIsEiMl9nAs+scj+IfNtKES7ITsA/wp26TaBDNEpkVwGrgV1XlvE1+PwW+D7zTdRC1UsD9SZYl+XbXYTSQucALwPXNUsJrkmzedah+LBLjI+s55ytt0gRKsgVwF3BmVb3SdR71V1Vrq2oeMAfYP4lLCiexJEcAq6tqWddZ1Nr8qtoX+ApwWrOUV5PbdGBf4Mqq2gd4DZj099xaJMbHKLDDOsdzgOc6yiJt8Jo19ncBN1fVz7vOo3aay/W/Aw7tOIrGNh84sllvfxtwUJKbuo2kQVTVc82/q4GF9JZga3IbBUbXuVK7gF6xmNQsEuPjEWC3JDs3N8ccDyzqOJO0QWpu2r0WWFVVl3WdR4NJMivJzObzGcAhwBPdptJYquqcqppTVTvR+732m6o6oeNY6iPJ5s1GFDRLY74MuDvhJFdV/wKeTbJ7c+pgYNJvIjK96wAbgqp6O8npwH3ANOC6qnqs41jqI8mtwIHAtklGgQuq6tpuU2kA84ETgZXNenuAc6vqng4zqb/tgRuaXe42Au6oKrcTlcbfp4CFvddcmA7cUlWLu42kAX0XuLl5Ufpp4OSO8/Tl9q+SJEmSWnNpkyRJkqTWLBKSJEmSWrNISJIkSWrNIiFJkiSpNYuEJEmSpNYsEpKkziU5MInbwUrSELFISJIkSWrNIiFJGliSE5I8nGRFkquSTEuyJsmlSZYneSDJrGbsvCQPJflLkoVJPtmc3zXJr5M82nzNLs3Db5FkQZInktzcvIs5SX6U5PHmcX7S0VOXJL2PRUKSNJAkewBfA+ZX1TxgLfBNYHNgeVXtCywBLmi+5Ebg7Kr6DLBynfM3A5dX1d7A54Hnm/P7AGcCnwbmAvOTbAMcDezZPM4PJ/ZZSpIGZZGQJA3qYOCzwCNJVjTHc4F3gNubMTcBX0iyNTCzqpY0528ADkiyJTC7qhYCVNUbVfXfZszDVTVaVe8AK4CdgFeAN4BrkhwDvDtWktQxi4QkaVABbqiqec3H7lV14XrGVZ/H+DBvrvP5WmB6Vb0N7A/cBRwFLG6ZWZI0QSwSkqRBPQAcm2Q7gCTbJNmR3u+SY5sx3wAerKqXgf8k+WJz/kRgSVW9AowmOap5jE8k2ezDvmGSLYCtq+oeesue5k3EE5MktTe96wCSpOFQVY8nOQ+4P8lGwP+A04DXgD2TLANepncfBcC3gJ81ReFp4OTm/InAVUkubh7juDG+7ZbA3Uk2pXc143vj/LQkSR9Rqsa6Ai1J0tiSrKmqLbrOIUn6eLm0SZIkSVJrXpGQJEmS1JpXJCRJkiS1ZpGQJEmS1JpFQpIkSVJrFglJkiRJrVkkJEmSJLX2f5R7SVKN4tqeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_loss(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,name,path):\n",
    "    model_json = model.to_json()\n",
    "    with open(path+name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "        model.save_weights(path+name+\".h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        \n",
    "def load_model(name,path):\n",
    "    from keras.models import model_from_json\n",
    "    # load json and create model\n",
    "    json_file = open(path+name+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path+name+\".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(NN,\"Pre_training\",\"models/review_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "NN = load_model(\"review_ratingPre_training\",\"models/\")\n",
    "NN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_loaded = load_model(\"labelled+books_final\",\"models/\")\n",
    "NN_loaded.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_loaded.evaluate(x_vec_test,y_vec_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation of the model for live prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence,word2Vec_model,model,max_len=50):\n",
    "    sentence = sentence.split(\" \")\n",
    "    good_sentence = []\n",
    "    unusued_words = []\n",
    "    for i in range(len(sentence)):\n",
    "        try :\n",
    "            sentence[i]=sentence[i].lower()\n",
    "            good_sentence.append(word2Vec_model.wv[sentence[i]])\n",
    "        except : \n",
    "            unusued_words.append(sentence[i])\n",
    "    sentence_length = len(good_sentence)\n",
    "    if(sentence_length<max_len):    \n",
    "        for j in range(max_len-sentence_length):\n",
    "            good_sentence.append([0]*300)\n",
    "\n",
    "    good_sentence = np.array(good_sentence)        \n",
    "    good_sentence = np.reshape(good_sentence, (1,good_sentence.shape[0], good_sentence.shape[1]))\n",
    "    return model.predict(good_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(score):\n",
    "    import numpy as np\n",
    "    neg=[]\n",
    "    pos=[]\n",
    "    for s in score :\n",
    "        neg.append(s[0][0])\n",
    "        pos.append(s[0][1])\n",
    "    sup_neg = [n for n in neg if n > 0.5]\n",
    "    sup_pos = [p for p in pos if p > 0.5]\n",
    "\n",
    "    return [np.mean(neg),np.mean(pos)]\n",
    "    \n",
    "def predict(sentence,word2Vec_model,model,max_len=50,word_length=300):\n",
    "    import numpy as np\n",
    "    sentence = sentence.split(\" \")\n",
    "    good_sentence = []\n",
    "    unusued_words = []\n",
    "    for i in range(len(sentence)):\n",
    "        try :\n",
    "            sentence[i]=sentence[i].lower()\n",
    "            good_sentence.append(word2Vec_model.wv[sentence[i]])\n",
    "        except : \n",
    "            unusued_words.append(sentence[i])\n",
    "    sentence_length = len(good_sentence)\n",
    "    \n",
    "    if(sentence_length<max_len):    \n",
    "        for j in range(max_len-sentence_length):\n",
    "            good_sentence.append([0]*word_length)     \n",
    "            \n",
    "    if (sentence_length > max_len) :\n",
    "        predictions = []\n",
    "        ind = 0\n",
    "        for i in range(int(np.ceil(sentence_length/max_len))):\n",
    "            sent_tmp = good_sentence[ind:ind+max_len]\n",
    "            if(len(sent_tmp)<max_len):\n",
    "                for j in range(max_len-len(sent_tmp)):\n",
    "                    sent_tmp.append([0]*word_length)    \n",
    "            sent_tmp = np.array(sent_tmp)        \n",
    "            sent_tmp = np.reshape(sent_tmp, (1,sent_tmp.shape[0], sent_tmp.shape[1]))\n",
    "            try :\n",
    "                predictions.append(model.predict(sent_tmp))\n",
    "                ind+=max_len                    \n",
    "            except : \n",
    "                print(\"Erreur au découpage no :\"+str(i))\n",
    "        return vote(predictions)\n",
    "    \n",
    "    good_sentence = np.array(good_sentence)        \n",
    "    good_sentence = np.reshape(good_sentence, (1,good_sentence.shape[0], good_sentence.shape[1]))\n",
    "    return np.squeeze(model.predict(good_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was amazing\n",
      " Négatif        Positif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2402942e-04 9.9957591e-01]\n"
     ]
    }
   ],
   "source": [
    "best=Final\n",
    "sentence =input()\n",
    "print(\" Négatif        Positif\")\n",
    "print(predict(sentence,model,best))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
